{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85ef655",
   "metadata": {},
   "source": [
    "# Phase 4: Adversarial Attacks & Robustness - Complete Evaluation\n",
    "\n",
    "**Project:** Tri-Objective Robust XAI for Medical Imaging  \n",
    "**Author:** Viraj Pankaj Jain  \n",
    "**Institution:** University of Glasgow  \n",
    "**Date:** November 26, 2025  \n",
    "**Platform:** Google Colab (T4 GPU)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This notebook implements **Phase 4.3, 4.4, and 4.5** of the research project:\n",
    "\n",
    "### Phase 4.3: Baseline Robustness Evaluation\n",
    "- Evaluate baseline models under adversarial attacks (FGSM, PGD, C&W, AutoAttack)\n",
    "- Test on ISIC 2018 dermoscopy dataset\n",
    "- Compute robust accuracy and attack success rates\n",
    "- Aggregate results across 3 seeds (42, 123, 456)\n",
    "- Expected: **50-70pp accuracy drop** under PGD √é¬µ=8/255\n",
    "\n",
    "### Phase 4.4: Attack Transferability Study  \n",
    "- Generate adversarial examples on ResNet-50\n",
    "- Test on EfficientNet-B0 (if available)\n",
    "- Compute cross-model attack success rates\n",
    "- Analyze transferability patterns\n",
    "\n",
    "### Phase 4.5: Adversarial Visualization\n",
    "- Visualize clean vs adversarial images\n",
    "- Amplify perturbations for visibility\n",
    "- Show prediction changes\n",
    "- Generate figures for dissertation\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "√¢≈ì‚Ä¶ **Phase 4.1 & 4.2 Complete:** All attacks implemented and tested (109/109 tests passing)  \n",
    "√¢≈ì‚Ä¶ **Phase 3 Complete:** Baseline models trained (3 seeds)  \n",
    "√¢≈ì‚Ä¶ **Infrastructure:** All code files ready in repository  \n",
    "√¢≈ì‚Ä¶ **Hardware:** Google Colab T4 GPU (16GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c72fe1",
   "metadata": {},
   "source": [
    "# Section 1: Environment Setup\n",
    "\n",
    "**Mount Google Drive and clone repository**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee85887",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mount failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3896698495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Verify GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: ENVIRONMENT SETUP (Google Colab A100)\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 4: ADVERSARIAL ATTACKS & ROBUSTNESS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"√¢≈ì‚Ä¶ Google Drive mounted\")\n",
    "\n",
    "# Clone repository\n",
    "REPO_PATH = Path('/content/tri-objective-robust-xai-medimg')\n",
    "if not REPO_PATH.exists():\n",
    "    !git clone https://github.com/viraj1011JAIN/tri-objective-robust-xai-medimg.git /content/tri-objective-robust-xai-medimg\n",
    "    print(\"√¢≈ì‚Ä¶ Repository cloned\")\n",
    "else:\n",
    "    !cd /content/tri-objective-robust-xai-medimg && git pull\n",
    "    print(\"√¢≈ì‚Ä¶ Repository updated\")\n",
    "\n",
    "PROJECT_ROOT = REPO_PATH\n",
    "os.chdir(PROJECT_ROOT)\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Verify GPU\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"\\n√¢≈ì‚Ä¶ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b35176",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies (Colab)\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q timm scikit-learn pandas matplotlib seaborn tqdm pillow mlflow albumentations\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbbd6a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: IMPORT LIBRARIES\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Optional: plotly for interactive plots\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    HAS_PLOTLY = True\n",
    "except ImportError:\n",
    "    HAS_PLOTLY = False\n",
    "    print(\"√¢≈°¬†√Ø¬∏¬è Plotly not available - using matplotlib only\")\n",
    "\n",
    "# Import project modules\n",
    "from src.attacks.fgsm import FGSM, FGSMConfig\n",
    "from src.attacks.pgd import PGD, PGDConfig\n",
    "from src.attacks.cw import CarliniWagner, CWConfig\n",
    "from src.datasets.isic import ISICDataset\n",
    "from src.models.build import build_model\n",
    "from src.utils.reproducibility import set_global_seed\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"√¢≈ì‚Ä¶ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846c6c1",
   "metadata": {},
   "source": [
    "# Section 2: Configuration\n",
    "\n",
    "**Define paths, hyperparameters, and attack configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c23fb",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Complete setup for Phase 4 evaluation\n",
    "# ============================================================================\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE 4 CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION DICTIONARY - All parameters defined here\n",
    "# ============================================================================\n",
    "CONFIG = {\n",
    "    # === Data Settings ===\n",
    "    'data_root': Path(\"/content/drive/MyDrive/data/data/isic_2018\"),\n",
    "    'checkpoint_dir': Path(\"/content/drive/MyDrive/checkpoints/baseline\"),\n",
    "    \n",
    "    # === Model Settings ===\n",
    "    'model_name': 'resnet50',\n",
    "    'num_classes': 7,\n",
    "    'image_size': 224,\n",
    "    \n",
    "    # === DataLoader Settings ===\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 0,  # Must be 0 for Google Drive\n",
    "    \n",
    "    # === Device ===\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    # === Seeds for reproducibility ===\n",
    "    'seeds': [42, 123, 456],\n",
    "    \n",
    "    # === FGSM Attack Parameters ===\n",
    "    'epsilons': [0.01, 0.02, 0.03, 0.05, 0.1],  # L‚àû perturbation budgets\n",
    "    \n",
    "    # === PGD Attack Parameters ===\n",
    "    'pgd_steps': [10, 20, 40],\n",
    "    'pgd_alpha': 0.01,\n",
    "    \n",
    "    # === C&W Attack Parameters ===\n",
    "    'cw_c': 1.0,\n",
    "    'cw_steps': 100,\n",
    "    'cw_lr': 0.01,\n",
    "    \n",
    "    # === Class Names ===\n",
    "    'class_names': ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'],\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# Create checkpoint directories on Drive\n",
    "# ============================================================================\n",
    "checkpoint_base = str(CONFIG['checkpoint_dir'])\n",
    "for seed in CONFIG['seeds']:\n",
    "    os.makedirs(f\"{checkpoint_base}/seed_{seed}\", exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# Verify checkpoints exist\n",
    "# ============================================================================\n",
    "print(\"\\nüìÅ Checkpoint Status:\")\n",
    "all_checkpoints_exist = True\n",
    "for seed in CONFIG['seeds']:\n",
    "    path = f\"{checkpoint_base}/seed_{seed}/best.pt\"\n",
    "    if os.path.exists(path):\n",
    "        size_mb = os.path.getsize(path) / (1024*1024)\n",
    "        print(f\"  ‚úÖ seed_{seed}/best.pt ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå seed_{seed}/best.pt - MISSING\")\n",
    "        all_checkpoints_exist = False\n",
    "\n",
    "# ============================================================================\n",
    "# Verify data exists\n",
    "# ============================================================================\n",
    "print(\"\\nüìÅ Data Status:\")\n",
    "data_root = CONFIG['data_root']\n",
    "metadata_path = data_root / \"metadata.csv\"\n",
    "if metadata_path.exists():\n",
    "    print(f\"  ‚úÖ metadata.csv found\")\n",
    "else:\n",
    "    print(f\"  ‚ùå metadata.csv - MISSING at {metadata_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONFIGURATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üìä Device: {CONFIG['device']}\")\n",
    "print(f\"üìÅ Data root: {CONFIG['data_root']}\")\n",
    "print(f\"üìÅ Checkpoints: {CONFIG['checkpoint_dir']}\")\n",
    "print(f\"üî¢ Seeds: {CONFIG['seeds']}\")\n",
    "print(f\"‚öîÔ∏è  Epsilons (FGSM/PGD): {CONFIG['epsilons']}\")\n",
    "print(f\"‚öîÔ∏è  PGD steps: {CONFIG['pgd_steps']}\")\n",
    "print(f\"üñºÔ∏è  Image size: {CONFIG['image_size']}\")\n",
    "print(f\"üì¶ Batch size: {CONFIG['batch_size']}\")\n",
    "\n",
    "if all_checkpoints_exist:\n",
    "    print(\"\\n‚úÖ ALL CHECKPOINTS FOUND - Ready to proceed!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  CHECKPOINTS MISSING - Run the upload cell below first!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e573af9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# UPLOAD CHECKPOINTS (Run this cell if checkpoints are missing)\n",
    "# ============================================================================\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "checkpoint_base = \"/content/drive/MyDrive/checkpoints/baseline\"\n",
    "\n",
    "# Upload for each seed that's missing\n",
    "for seed in [42, 123, 456]:\n",
    "    checkpoint_path = f\"{checkpoint_base}/seed_{seed}/best.pt\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üì§ Upload best.pt for SEED {seed}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Select the file: checkpoints/baseline/seed_{seed}/best.pt from your computer\")\n",
    "        \n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        for filename in uploaded.keys():\n",
    "            # Save to the correct location\n",
    "            dest_path = f\"{checkpoint_base}/seed_{seed}/best.pt\"\n",
    "            with open(dest_path, 'wb') as f:\n",
    "                f.write(uploaded[filename])\n",
    "            print(f\"‚úÖ Saved to: {dest_path}\")\n",
    "            \n",
    "            # Verify file size\n",
    "            size_mb = os.path.getsize(dest_path) / (1024*1024)\n",
    "            print(f\"üìä File size: {size_mb:.1f} MB\")\n",
    "    else:\n",
    "        print(f\"‚úÖ seed_{seed}/best.pt already exists, skipping...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ UPLOAD COMPLETE! Now re-run the Configuration cell above,\")\n",
    "print(\"   then continue with Data Loading and Evaluation cells.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec3814d",
   "metadata": {},
   "source": [
    "# Section 3: Helper Functions\n",
    "\n",
    "**Utility functions for evaluation and visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a409fd96",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_checkpoint(\n",
    "    checkpoint_path: str,\n",
    "    model_name: str = \"resnet50\",\n",
    "    num_classes: int = 7,\n",
    "    device: str = \"cuda\"\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Load model from checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to checkpoint file\n",
    "        model_name: Model architecture name\n",
    "        num_classes: Number of output classes\n",
    "        device: Device to load model on\n",
    "        \n",
    "    Returns:\n",
    "        Loaded model in eval mode\n",
    "    \"\"\"\n",
    "    print(f\"Loading model from: {checkpoint_path}\")\n",
    "    \n",
    "    # Build model - use 'architecture' parameter (not 'model_name')\n",
    "    model = build_model(\n",
    "        architecture=model_name,  # Fixed: use 'architecture' not 'model_name'\n",
    "        num_classes=num_classes,\n",
    "        pretrained=False\n",
    "    )\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    elif 'state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_accuracy(\n",
    "    model: nn.Module,\n",
    "    images: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    device: str = \"cuda\"\n",
    ") -> float:\n",
    "    \"\"\"Compute accuracy for a batch.\"\"\"\n",
    "    model.eval()\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(images)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        accuracy = (preds == labels).float().mean().item()\n",
    "    \n",
    "    return accuracy * 100\n",
    "\n",
    "\n",
    "def evaluate_attack(\n",
    "    model: nn.Module,\n",
    "    attack,\n",
    "    dataloader: DataLoader,\n",
    "    device: str = \"cuda\",\n",
    "    max_batches: Optional[int] = None\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a model under adversarial attack.\n",
    "    \n",
    "    Args:\n",
    "        model: Model to evaluate\n",
    "        attack: Attack instance (FGSM, PGD, CW, etc.)\n",
    "        dataloader: Test data loader\n",
    "        device: Device for computation\n",
    "        max_batches: Maximum number of batches (None for all)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_clean_correct = 0\n",
    "    total_adv_correct = 0\n",
    "    total_samples = 0\n",
    "    total_l2_dist = 0\n",
    "    total_linf_dist = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Evaluating {attack.name}\", leave=False)\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(pbar):\n",
    "        if max_batches and batch_idx >= max_batches:\n",
    "            break\n",
    "        \n",
    "        # Handle both (images, labels) and (images, labels, meta) formats\n",
    "        if len(batch_data) == 2:\n",
    "            images, labels = batch_data\n",
    "        else:\n",
    "            images, labels, _ = batch_data  # Ignore metadata\n",
    "            \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        # Clean accuracy\n",
    "        with torch.no_grad():\n",
    "            clean_logits = model(images)\n",
    "            clean_preds = clean_logits.argmax(dim=1)\n",
    "            clean_correct = (clean_preds == labels).sum().item()\n",
    "        \n",
    "        # Generate adversarial examples\n",
    "        adv_images = attack(model, images, labels)\n",
    "        \n",
    "        # Adversarial accuracy\n",
    "        with torch.no_grad():\n",
    "            adv_logits = model(adv_images)\n",
    "            adv_preds = adv_logits.argmax(dim=1)\n",
    "            adv_correct = (adv_preds == labels).sum().item()\n",
    "        \n",
    "        # Perturbation norms\n",
    "        perturbation = adv_images - images\n",
    "        l2_dist = torch.norm(perturbation.view(batch_size, -1), p=2, dim=1).mean().item()\n",
    "        linf_dist = perturbation.abs().view(batch_size, -1).max(dim=1)[0].mean().item()\n",
    "        \n",
    "        total_clean_correct += clean_correct\n",
    "        total_adv_correct += adv_correct\n",
    "        total_samples += batch_size\n",
    "        total_l2_dist += l2_dist * batch_size\n",
    "        total_linf_dist += linf_dist * batch_size\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'clean_acc': f'{100*total_clean_correct/total_samples:.1f}%',\n",
    "            'adv_acc': f'{100*total_adv_correct/total_samples:.1f}%'\n",
    "        })\n",
    "    \n",
    "    clean_accuracy = 100 * total_clean_correct / total_samples\n",
    "    adv_accuracy = 100 * total_adv_correct / total_samples\n",
    "    attack_success_rate = 100 * (1 - total_adv_correct / total_clean_correct) if total_clean_correct > 0 else 0\n",
    "    \n",
    "    results = {\n",
    "        'clean_accuracy': clean_accuracy,\n",
    "        'robust_accuracy': adv_accuracy,\n",
    "        'accuracy_drop': clean_accuracy - adv_accuracy,\n",
    "        'attack_success_rate': attack_success_rate,\n",
    "        'mean_l2_dist': total_l2_dist / total_samples,\n",
    "        'mean_linf_dist': total_linf_dist / total_samples,\n",
    "        'total_samples': total_samples\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def aggregate_seed_results(\n",
    "    seed_results: Dict[int, Dict[str, float]],\n",
    "    metric_names: List[str]\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Aggregate results across seeds.\n",
    "    \n",
    "    Args:\n",
    "        seed_results: Dictionary mapping seed to results\n",
    "        metric_names: List of metric names to aggregate\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with mean and std for each metric\n",
    "    \"\"\"\n",
    "    aggregated = {}\n",
    "    \n",
    "    for metric in metric_names:\n",
    "        values = [seed_results[seed][metric] for seed in seed_results]\n",
    "        aggregated[metric] = {\n",
    "            'mean': np.mean(values),\n",
    "            'std': np.std(values),\n",
    "            'values': values\n",
    "        }\n",
    "    \n",
    "    return aggregated\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb1297",
   "metadata": {},
   "source": [
    "# Section 4: Load Data and Model\n",
    "\n",
    "**Load ISIC2018 test set and baseline checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6167a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA LOADING - ISIC2018 Test Dataset\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING ISIC2018 TEST DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ============================================================================\n",
    "# Fix Windows backslashes in metadata for Linux/Colab\n",
    "# ============================================================================\n",
    "metadata_path = CONFIG['data_root'] / \"metadata.csv\"\n",
    "print(f\"\\nüìÑ Reading metadata from: {metadata_path}\")\n",
    "\n",
    "df = pd.read_csv(metadata_path)\n",
    "print(f\"   Total rows: {len(df)}\")\n",
    "\n",
    "# Convert Windows backslashes to forward slashes\n",
    "if 'image_path' in df.columns:\n",
    "    df['image_path'] = df['image_path'].str.replace('\\\\', '/', regex=False)\n",
    "    print(\"   ‚úÖ Converted backslashes to forward slashes\")\n",
    "\n",
    "# Save fixed metadata\n",
    "fixed_metadata_path = CONFIG['data_root'] / \"metadata_fixed.csv\"\n",
    "df.to_csv(fixed_metadata_path, index=False)\n",
    "print(f\"   ‚úÖ Saved fixed metadata to: {fixed_metadata_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Create Albumentations transform pipeline\n",
    "# ============================================================================\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(CONFIG['image_size'], CONFIG['image_size']),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ============================================================================\n",
    "# Create Dataset and DataLoader\n",
    "# ============================================================================\n",
    "print(\"\\nüì¶ Creating dataset...\")\n",
    "\n",
    "test_dataset = ISICDataset(\n",
    "    root=str(CONFIG['data_root']),\n",
    "    split='test',\n",
    "    transforms=test_transforms,\n",
    "    csv_path=str(fixed_metadata_path),\n",
    "    image_column='image_path',\n",
    "    label_column='label'\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATASET LOADED SUCCESSFULLY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üìä Test samples: {len(test_dataset)}\")\n",
    "print(f\"üì¶ Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"üî¢ Number of batches: {len(test_loader)}\")\n",
    "print(f\"üè∑Ô∏è  Classes ({len(test_dataset.class_names)}): {test_dataset.class_names}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e14655",
   "metadata": {},
   "source": [
    "# Section 5: Phase 4.3 - Baseline Robustness Evaluation\n",
    "\n",
    "**Evaluate all attacks on baseline models (3 seeds)**\n",
    "\n",
    "Expected results:\n",
    "- Clean accuracy: ~80-85%\n",
    "- FGSM √é¬µ=8/255: ~30-35% (50pp drop)\n",
    "- PGD √é¬µ=8/255: ~10-20% (65pp drop)\n",
    "- C&W: ~5-15% (70pp drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf94cd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE ADVERSARIAL EVALUATION - All attacks, all seeds\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE 4: ADVERSARIAL ROBUSTNESS EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize results storage\n",
    "all_results = {\n",
    "    'clean': [],\n",
    "    'FGSM': {eps: [] for eps in CONFIG['epsilons']},\n",
    "    'PGD': {f\"eps{eps}_steps{steps}\": [] \n",
    "            for eps in CONFIG['epsilons'] \n",
    "            for steps in CONFIG['pgd_steps']},\n",
    "    'CW': []\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"\\nüïê Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üìä Evaluating {len(CONFIG['seeds'])} seeds: {CONFIG['seeds']}\")\n",
    "print(f\"‚öîÔ∏è  FGSM: {len(CONFIG['epsilons'])} epsilon values\")\n",
    "print(f\"‚öîÔ∏è  PGD: {len(CONFIG['epsilons'])} √ó {len(CONFIG['pgd_steps'])} = {len(CONFIG['epsilons']) * len(CONFIG['pgd_steps'])} configurations\")\n",
    "print(f\"‚öîÔ∏è  C&W: 1 configuration\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EVALUATION LOOP - Iterate over seeds\n",
    "# ============================================================================\n",
    "for seed_idx, seed in enumerate(CONFIG['seeds']):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SEED {seed} ({seed_idx+1}/{len(CONFIG['seeds'])})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Load model checkpoint\n",
    "    checkpoint_path = f\"{CONFIG['checkpoint_dir']}/seed_{seed}/best.pt\"\n",
    "    print(f\"\\nüìÇ Loading: {checkpoint_path}\")\n",
    "    \n",
    "    model = load_model_and_checkpoint(\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        model_name=CONFIG['model_name'],\n",
    "        num_classes=CONFIG['num_classes'],\n",
    "        device=CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Clean Accuracy\n",
    "    # ========================================================================\n",
    "    print(\"\\nüìä Evaluating Clean Accuracy...\")\n",
    "    clean_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(test_loader, desc=\"Clean eval\", leave=False):\n",
    "            # Handle (images, labels, meta) format from ISICDataset\n",
    "            if len(batch_data) == 2:\n",
    "                images, labels = batch_data\n",
    "            else:\n",
    "                images, labels, _ = batch_data  # Ignore metadata\n",
    "                \n",
    "            images = images.to(CONFIG['device'])\n",
    "            labels = labels.to(CONFIG['device'])\n",
    "            logits = model(images)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            clean_correct += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    clean_acc = 100 * clean_correct / total_samples\n",
    "    all_results['clean'].append({'accuracy': clean_acc, 'seed': seed})\n",
    "    print(f\"‚úÖ Clean Accuracy: {clean_acc:.2f}%\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FGSM Attack Evaluation\n",
    "    # ========================================================================\n",
    "    print(f\"\\nüî• FGSM Attack Evaluation\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epsilon in CONFIG['epsilons']:\n",
    "        # Create FGSM config and attack\n",
    "        fgsm_config = FGSMConfig(\n",
    "            epsilon=epsilon,\n",
    "            clip_min=0.0,\n",
    "            clip_max=1.0,\n",
    "            targeted=False,\n",
    "            device=CONFIG['device']\n",
    "        )\n",
    "        fgsm_attack = FGSM(fgsm_config)\n",
    "        \n",
    "        fgsm_results = evaluate_attack(\n",
    "            model=model,\n",
    "            attack=fgsm_attack,\n",
    "            dataloader=test_loader,\n",
    "            device=CONFIG['device']\n",
    "        )\n",
    "        fgsm_results['seed'] = seed\n",
    "        fgsm_results['epsilon'] = epsilon\n",
    "        all_results['FGSM'][epsilon].append(fgsm_results)\n",
    "        \n",
    "        print(f\"  Œµ={epsilon:.3f}: Robust={fgsm_results['robust_accuracy']:.1f}% | Drop={fgsm_results['accuracy_drop']:.1f}pp\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PGD Attack Evaluation\n",
    "    # ========================================================================\n",
    "    print(f\"\\nüî• PGD Attack Evaluation\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epsilon in CONFIG['epsilons']:\n",
    "        for num_steps in CONFIG['pgd_steps']:\n",
    "            # Create PGD config and attack\n",
    "            pgd_config = PGDConfig(\n",
    "                epsilon=epsilon,\n",
    "                num_steps=num_steps,\n",
    "                step_size=epsilon/4,\n",
    "                random_start=True,\n",
    "                clip_min=0.0,\n",
    "                clip_max=1.0,\n",
    "                targeted=False,\n",
    "                device=CONFIG['device']\n",
    "            )\n",
    "            pgd_attack = PGD(pgd_config)\n",
    "            \n",
    "            pgd_results = evaluate_attack(\n",
    "                model=model,\n",
    "                attack=pgd_attack,\n",
    "                dataloader=test_loader,\n",
    "                device=CONFIG['device']\n",
    "            )\n",
    "            pgd_results['seed'] = seed\n",
    "            pgd_results['epsilon'] = epsilon\n",
    "            pgd_results['steps'] = num_steps\n",
    "            \n",
    "            config_key = f\"eps{epsilon}_steps{num_steps}\"\n",
    "            all_results['PGD'][config_key].append(pgd_results)\n",
    "            \n",
    "            print(f\"  Œµ={epsilon:.3f}, steps={num_steps}: Robust={pgd_results['robust_accuracy']:.1f}% | Drop={pgd_results['accuracy_drop']:.1f}pp\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # C&W Attack Evaluation (on subset for speed)\n",
    "    # ========================================================================\n",
    "    print(f\"\\nüî• C&W Attack Evaluation\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Create C&W config and attack\n",
    "    # Note: C&W uses L2 norm, not L‚àû\n",
    "    # - confidence (kappa): margin for misclassification (0 = just misclassify)\n",
    "    # - initial_c: initial penalty parameter (tuned via binary search)\n",
    "    cw_config = CWConfig(\n",
    "        epsilon=0.5,  # L2 budget (not L‚àû)\n",
    "        confidence=0.0,  # kappa (confidence margin)\n",
    "        learning_rate=CONFIG['cw_lr'],\n",
    "        max_iterations=CONFIG['cw_steps'],\n",
    "        binary_search_steps=5,\n",
    "        initial_c=CONFIG['cw_c'],  # Initial penalty parameter\n",
    "        abort_early=True,\n",
    "        targeted=False,\n",
    "        device=CONFIG['device']\n",
    "    )\n",
    "    cw_attack = CarliniWagner(cw_config)\n",
    "    \n",
    "    # Evaluate on subset (C&W is slow)\n",
    "    cw_results = evaluate_attack(\n",
    "        model=model,\n",
    "        attack=cw_attack,\n",
    "        dataloader=test_loader,\n",
    "        device=CONFIG['device'],\n",
    "        max_batches=10  # Limit to 10 batches for speed\n",
    "    )\n",
    "    cw_results['seed'] = seed\n",
    "    all_results['CW'].append(cw_results)\n",
    "    \n",
    "    print(f\"  C&W: Robust={cw_results['robust_accuracy']:.1f}% | Drop={cw_results['accuracy_drop']:.1f}pp | L2={cw_results['mean_l2_dist']:.4f}\")\n",
    "    \n",
    "    # Free GPU memory\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"EVALUATION COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"‚è±Ô∏è  Total time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"üìä Seeds evaluated: {CONFIG['seeds']}\")\n",
    "print(f\"\\nüìà Clean Accuracy Summary:\")\n",
    "clean_accs = [r['accuracy'] for r in all_results['clean']]\n",
    "print(f\"   Mean: {np.mean(clean_accs):.2f}% ¬± {np.std(clean_accs):.2f}%\")\n",
    "\n",
    "print(f\"\\nüìà FGSM Robust Accuracy (Œµ=0.03):\")\n",
    "if 0.03 in all_results['FGSM']:\n",
    "    fgsm_accs = [r['robust_accuracy'] for r in all_results['FGSM'][0.03]]\n",
    "    print(f\"   Mean: {np.mean(fgsm_accs):.2f}% ¬± {np.std(fgsm_accs):.2f}%\")\n",
    "\n",
    "print(f\"\\nüìà PGD Robust Accuracy (Œµ=0.03, steps=20):\")\n",
    "key = \"eps0.03_steps20\"\n",
    "if key in all_results['PGD']:\n",
    "    pgd_accs = [r['robust_accuracy'] for r in all_results['PGD'][key]]\n",
    "    print(f\"   Mean: {np.mean(pgd_accs):.2f}% ¬± {np.std(pgd_accs):.2f}%\")\n",
    "\n",
    "print(f\"\\nüìà C&W Robust Accuracy:\")\n",
    "cw_accs = [r['robust_accuracy'] for r in all_results['CW']]\n",
    "print(f\"   Mean: {np.mean(cw_accs):.2f}% ¬± {np.std(cw_accs):.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to 'all_results' dictionary\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ad1ac",
   "metadata": {},
   "source": [
    "## 5.1: FGSM Attack Evaluation\n",
    "\n",
    "**Fast Gradient Sign Method - Single step L√¢ÀÜ≈æ attack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa266026",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FGSM RESULTS SUMMARY TABLE\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"FGSM ATTACK RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create summary table\n",
    "fgsm_summary = []\n",
    "for epsilon in CONFIG['epsilons']:\n",
    "    results = all_results['FGSM'][epsilon]\n",
    "    robust_accs = [r['robust_accuracy'] for r in results]\n",
    "    drops = [r['accuracy_drop'] for r in results]\n",
    "    success_rates = [r['attack_success_rate'] for r in results]\n",
    "    \n",
    "    fgsm_summary.append({\n",
    "        'Epsilon': f\"{epsilon:.3f}\",\n",
    "        'Œµ (8-bit)': f\"{epsilon*255:.1f}/255\",\n",
    "        'Robust Acc (%)': f\"{np.mean(robust_accs):.2f} ¬± {np.std(robust_accs):.2f}\",\n",
    "        'Acc Drop (pp)': f\"{np.mean(drops):.2f} ¬± {np.std(drops):.2f}\",\n",
    "        'Attack Success (%)': f\"{np.mean(success_rates):.2f} ¬± {np.std(success_rates):.2f}\",\n",
    "    })\n",
    "\n",
    "fgsm_df = pd.DataFrame(fgsm_summary)\n",
    "print(\"\\nüìä FGSM Results Across All Seeds:\")\n",
    "print(fgsm_df.to_string(index=False))\n",
    "\n",
    "# Latex table for dissertation\n",
    "print(\"\\nüìù LaTeX Table:\")\n",
    "print(fgsm_df.to_latex(index=False, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8518d62",
   "metadata": {},
   "source": [
    "## 5.2: PGD Attack Evaluation\n",
    "\n",
    "**Projected Gradient Descent - Multi-step iterative attack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4087e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PGD RESULTS SUMMARY TABLE\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"PGD ATTACK RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create summary table\n",
    "pgd_summary = []\n",
    "for epsilon in CONFIG['epsilons']:\n",
    "    for steps in CONFIG['pgd_steps']:\n",
    "        key = f\"eps{epsilon}_steps{steps}\"\n",
    "        results = all_results['PGD'][key]\n",
    "        robust_accs = [r['robust_accuracy'] for r in results]\n",
    "        drops = [r['accuracy_drop'] for r in results]\n",
    "        success_rates = [r['attack_success_rate'] for r in results]\n",
    "        \n",
    "        pgd_summary.append({\n",
    "            'Epsilon': f\"{epsilon:.3f}\",\n",
    "            'Steps': steps,\n",
    "            'Robust Acc (%)': f\"{np.mean(robust_accs):.2f} ¬± {np.std(robust_accs):.2f}\",\n",
    "            'Acc Drop (pp)': f\"{np.mean(drops):.2f} ¬± {np.std(drops):.2f}\",\n",
    "            'Attack Success (%)': f\"{np.mean(success_rates):.2f} ¬± {np.std(success_rates):.2f}\",\n",
    "        })\n",
    "\n",
    "pgd_df = pd.DataFrame(pgd_summary)\n",
    "print(\"\\nüìä PGD Results Across All Seeds:\")\n",
    "print(pgd_df.to_string(index=False))\n",
    "\n",
    "# Show key configurations\n",
    "print(\"\\nüìå Key Configurations:\")\n",
    "for eps in [0.03, 0.05]:\n",
    "    for steps in [20, 40]:\n",
    "        key = f\"eps{eps}_steps{steps}\"\n",
    "        if key in all_results['PGD']:\n",
    "            results = all_results['PGD'][key]\n",
    "            robust_accs = [r['robust_accuracy'] for r in results]\n",
    "            print(f\"   Œµ={eps}, steps={steps}: {np.mean(robust_accs):.2f}% ¬± {np.std(robust_accs):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d82d595",
   "metadata": {},
   "source": [
    "## 5.3: C&W Attack Evaluation\n",
    "\n",
    "**Carlini & Wagner - L2 optimization-based attack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5289a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C&W RESULTS SUMMARY\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"C&W ATTACK RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract C&W results\n",
    "cw_results_list = all_results['CW']\n",
    "\n",
    "robust_accs = [r['robust_accuracy'] for r in cw_results_list]\n",
    "drops = [r['accuracy_drop'] for r in cw_results_list]\n",
    "success_rates = [r['attack_success_rate'] for r in cw_results_list]\n",
    "l2_dists = [r['mean_l2_dist'] for r in cw_results_list]\n",
    "\n",
    "print(f\"\\nüìä C&W Attack Results (L2 optimization-based):\")\n",
    "print(f\"   Configuration: c={CONFIG['cw_c']}, steps={CONFIG['cw_steps']}, lr={CONFIG['cw_lr']}\")\n",
    "print(f\"\\n   Robust Accuracy: {np.mean(robust_accs):.2f}% ¬± {np.std(robust_accs):.2f}%\")\n",
    "print(f\"   Accuracy Drop: {np.mean(drops):.2f}pp ¬± {np.std(drops):.2f}pp\")\n",
    "print(f\"   Attack Success Rate: {np.mean(success_rates):.2f}% ¬± {np.std(success_rates):.2f}%\")\n",
    "print(f\"   Mean L2 Distance: {np.mean(l2_dists):.4f} ¬± {np.std(l2_dists):.4f}\")\n",
    "\n",
    "print(\"\\nüìà Per-Seed Breakdown:\")\n",
    "for r in cw_results_list:\n",
    "    print(f\"   Seed {r['seed']}: Robust={r['robust_accuracy']:.2f}%, L2={r['mean_l2_dist']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c6686",
   "metadata": {},
   "source": [
    "# Section 6: Statistical Aggregation\n",
    "\n",
    "**Aggregate results across 3 seeds and compute statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b56a21",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STATISTICAL AGGREGATION - Results across 3 seeds\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"STATISTICAL AGGREGATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# Clean Accuracy Summary\n",
    "# ============================================================================\n",
    "print(\"\\nüìä CLEAN ACCURACY:\")\n",
    "clean_accs = [r['accuracy'] for r in all_results['clean']]\n",
    "print(f\"   Mean: {np.mean(clean_accs):.2f}% ¬± {np.std(clean_accs):.2f}%\")\n",
    "for r in all_results['clean']:\n",
    "    print(f\"   Seed {r['seed']}: {r['accuracy']:.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# FGSM Summary\n",
    "# ============================================================================\n",
    "print(\"\\nüìä FGSM ATTACK SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "for epsilon in CONFIG['epsilons']:\n",
    "    results = all_results['FGSM'][epsilon]\n",
    "    robust_accs = [r['robust_accuracy'] for r in results]\n",
    "    drops = [r['accuracy_drop'] for r in results]\n",
    "    print(f\"   Œµ={epsilon:.3f}: Robust={np.mean(robust_accs):.2f}% ¬± {np.std(robust_accs):.2f}% | Drop={np.mean(drops):.2f}pp\")\n",
    "\n",
    "# ============================================================================\n",
    "# PGD Summary\n",
    "# ============================================================================\n",
    "print(\"\\nüìä PGD ATTACK SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "for epsilon in CONFIG['epsilons']:\n",
    "    for steps in CONFIG['pgd_steps']:\n",
    "        key = f\"eps{epsilon}_steps{steps}\"\n",
    "        results = all_results['PGD'][key]\n",
    "        robust_accs = [r['robust_accuracy'] for r in results]\n",
    "        drops = [r['accuracy_drop'] for r in results]\n",
    "        print(f\"   Œµ={epsilon:.3f}, steps={steps}: Robust={np.mean(robust_accs):.2f}% ¬± {np.std(robust_accs):.2f}% | Drop={np.mean(drops):.2f}pp\")\n",
    "\n",
    "# ============================================================================\n",
    "# C&W Summary\n",
    "# ============================================================================\n",
    "print(\"\\nüìä C&W ATTACK SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "results = all_results['CW']\n",
    "robust_accs = [r['robust_accuracy'] for r in results]\n",
    "l2_dists = [r['mean_l2_dist'] for r in results]\n",
    "print(f\"   Robust Accuracy: {np.mean(robust_accs):.2f}% ¬± {np.std(robust_accs):.2f}%\")\n",
    "print(f\"   Mean L2 Distance: {np.mean(l2_dists):.4f} ¬± {np.std(l2_dists):.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Key Findings for Dissertation\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY FINDINGS FOR DISSERTATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Best performing attack config\n",
    "best_fgsm_eps = 0.03  # Standard benchmark\n",
    "fgsm_03 = all_results['FGSM'].get(0.03, [])\n",
    "if fgsm_03:\n",
    "    print(f\"\\nüéØ FGSM (Œµ=0.03): {np.mean([r['robust_accuracy'] for r in fgsm_03]):.2f}%\")\n",
    "\n",
    "pgd_key = \"eps0.03_steps20\"\n",
    "if pgd_key in all_results['PGD']:\n",
    "    pgd_results = all_results['PGD'][pgd_key]\n",
    "    print(f\"üéØ PGD (Œµ=0.03, 20 steps): {np.mean([r['robust_accuracy'] for r in pgd_results]):.2f}%\")\n",
    "\n",
    "cw_results = all_results['CW']\n",
    "if cw_results:\n",
    "    print(f\"üéØ C&W: {np.mean([r['robust_accuracy'] for r in cw_results]):.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Statistical aggregation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50249da0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAVE RESULTS TO JSON\n",
    "# ============================================================================\n",
    "import json\n",
    "\n",
    "# Create results directory on Google Drive\n",
    "results_dir = \"/content/drive/MyDrive/results/phase4_adversarial\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "results_json_path = f\"{results_dir}/baseline_robustness_aggregated.json\"\n",
    "\n",
    "# Convert to serializable format\n",
    "results_serializable = {\n",
    "    'clean': {\n",
    "        'mean': float(np.mean([r['accuracy'] for r in all_results['clean']])),\n",
    "        'std': float(np.std([r['accuracy'] for r in all_results['clean']])),\n",
    "        'values': [float(r['accuracy']) for r in all_results['clean']]\n",
    "    },\n",
    "    'FGSM': {},\n",
    "    'PGD': {},\n",
    "    'CW': {}\n",
    "}\n",
    "\n",
    "# FGSM results\n",
    "for epsilon in CONFIG['epsilons']:\n",
    "    eps_key = str(epsilon)\n",
    "    results = all_results['FGSM'][epsilon]\n",
    "    results_serializable['FGSM'][eps_key] = {\n",
    "        'robust_accuracy': {\n",
    "            'mean': float(np.mean([r['robust_accuracy'] for r in results])),\n",
    "            'std': float(np.std([r['robust_accuracy'] for r in results])),\n",
    "        },\n",
    "        'accuracy_drop': {\n",
    "            'mean': float(np.mean([r['accuracy_drop'] for r in results])),\n",
    "            'std': float(np.std([r['accuracy_drop'] for r in results])),\n",
    "        }\n",
    "    }\n",
    "\n",
    "# PGD results\n",
    "for epsilon in CONFIG['epsilons']:\n",
    "    for steps in CONFIG['pgd_steps']:\n",
    "        key = f\"eps{epsilon}_steps{steps}\"\n",
    "        results = all_results['PGD'][key]\n",
    "        results_serializable['PGD'][key] = {\n",
    "            'robust_accuracy': {\n",
    "                'mean': float(np.mean([r['robust_accuracy'] for r in results])),\n",
    "                'std': float(np.std([r['robust_accuracy'] for r in results])),\n",
    "            },\n",
    "            'accuracy_drop': {\n",
    "                'mean': float(np.mean([r['accuracy_drop'] for r in results])),\n",
    "                'std': float(np.std([r['accuracy_drop'] for r in results])),\n",
    "            }\n",
    "        }\n",
    "\n",
    "# C&W results\n",
    "results = all_results['CW']\n",
    "results_serializable['CW'] = {\n",
    "    'robust_accuracy': {\n",
    "        'mean': float(np.mean([r['robust_accuracy'] for r in results])),\n",
    "        'std': float(np.std([r['robust_accuracy'] for r in results])),\n",
    "    },\n",
    "    'mean_l2_dist': {\n",
    "        'mean': float(np.mean([r['mean_l2_dist'] for r in results])),\n",
    "        'std': float(np.std([r['mean_l2_dist'] for r in results])),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save\n",
    "with open(results_json_path, 'w') as f:\n",
    "    json.dump(results_serializable, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Results saved to: {results_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4aa05",
   "metadata": {},
   "source": [
    "# Section 7: Phase 4.5 - Adversarial Visualization\n",
    "\n",
    "**Generate and visualize adversarial examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1bab3",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL: PhD-LEVEL VISUALIZATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Publication-quality settings\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 11,\n",
    "    'figure.titlesize': 18,\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "})\n",
    "\n",
    "# Color palette for publication\n",
    "COLORS = {\n",
    "    'clean': '#2ecc71',      # Green\n",
    "    'fgsm': '#e74c3c',       # Red\n",
    "    'pgd': '#9b59b6',        # Purple\n",
    "    'cw': '#f39c12',         # Orange\n",
    "    'baseline': '#3498db',   # Blue\n",
    "    'robust': '#1abc9c',     # Teal\n",
    "}\n",
    "\n",
    "def denormalize_image(img_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    \"\"\"Denormalize image tensor for visualization.\"\"\"\n",
    "    img = img_tensor.clone()\n",
    "    for t, m, s in zip(img, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return torch.clamp(img, 0, 1)\n",
    "\n",
    "\n",
    "def create_phd_adversarial_figure(model, images, labels, attacks_dict, class_names=None, num_samples=5):\n",
    "    \"\"\"\n",
    "    Create publication-quality adversarial examples figure.\n",
    "    PhD-level visualization with detailed annotations.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    images = images[:num_samples].to(device)\n",
    "    labels = labels[:num_samples].to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        clean_logits = model(images)\n",
    "        clean_preds = clean_logits.argmax(dim=1)\n",
    "        clean_probs = torch.softmax(clean_logits, dim=1)\n",
    "        clean_confs = clean_probs.max(dim=1)[0]\n",
    "    \n",
    "    # Generate adversarial examples\n",
    "    adv_data = {}\n",
    "    for name, attack in attacks_dict.items():\n",
    "        adv_imgs = attack(model, images, labels)\n",
    "        with torch.no_grad():\n",
    "            adv_logits = model(adv_imgs)\n",
    "            adv_preds = adv_logits.argmax(dim=1)\n",
    "            adv_confs = torch.softmax(adv_logits, dim=1).max(dim=1)[0]\n",
    "        adv_data[name] = {\n",
    "            'images': adv_imgs,\n",
    "            'preds': adv_preds,\n",
    "            'confs': adv_confs,\n",
    "            'perturbation': (adv_imgs - images).abs()\n",
    "        }\n",
    "    \n",
    "    # Create figure with GridSpec\n",
    "    num_cols = len(attacks_dict) + 2  # Clean + attacks + perturbation\n",
    "    fig = plt.figure(figsize=(4*num_cols, 4.5*num_samples))\n",
    "    gs = GridSpec(num_samples, num_cols, figure=fig, hspace=0.3, wspace=0.1)\n",
    "    \n",
    "    class_labels = class_names if class_names else [f'Class {i}' for i in range(7)]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Clean image\n",
    "        ax = fig.add_subplot(gs[i, 0])\n",
    "        clean_img = denormalize_image(images[i].cpu()).permute(1, 2, 0).numpy()\n",
    "        ax.imshow(clean_img)\n",
    "        \n",
    "        true_label = labels[i].item()\n",
    "        pred_label = clean_preds[i].item()\n",
    "        conf = clean_confs[i].item() * 100\n",
    "        \n",
    "        title_color = 'green' if pred_label == true_label else 'red'\n",
    "        ax.set_title(f'Clean Image\\nTrue: {class_labels[true_label]}\\nPred: {class_labels[pred_label]} ({conf:.1f}%)', \n",
    "                    fontsize=10, color=title_color, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Add green border for correct\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_color('green')\n",
    "            spine.set_linewidth(3)\n",
    "        \n",
    "        # Adversarial examples\n",
    "        for j, (name, data) in enumerate(adv_data.items(), start=1):\n",
    "            ax = fig.add_subplot(gs[i, j])\n",
    "            adv_img = denormalize_image(data['images'][i].cpu()).permute(1, 2, 0).numpy()\n",
    "            ax.imshow(adv_img)\n",
    "            \n",
    "            adv_pred = data['preds'][i].item()\n",
    "            adv_conf = data['confs'][i].item() * 100\n",
    "            \n",
    "            # Success indicator\n",
    "            attack_success = adv_pred != true_label\n",
    "            border_color = 'red' if attack_success else 'green'\n",
    "            title_color = 'red' if attack_success else 'green'\n",
    "            \n",
    "            linf = data['perturbation'][i].max().item()\n",
    "            l2 = torch.norm(data['perturbation'][i]).item()\n",
    "            \n",
    "            ax.set_title(f'{name}\\nPred: {class_labels[adv_pred]} ({adv_conf:.1f}%)\\n'\n",
    "                        f'L√¢ÀÜ≈æ={linf:.4f}, L√¢‚Äö‚Äö={l2:.2f}', \n",
    "                        fontsize=9, color=title_color, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(True)\n",
    "                spine.set_color(border_color)\n",
    "                spine.set_linewidth(3)\n",
    "        \n",
    "        # Perturbation heatmap (last column)\n",
    "        ax = fig.add_subplot(gs[i, -1])\n",
    "        # Use strongest attack perturbation\n",
    "        strongest_attack = list(adv_data.keys())[-1]\n",
    "        pert = adv_data[strongest_attack]['perturbation'][i].cpu()\n",
    "        pert_magnitude = pert.norm(dim=0).numpy()  # L2 norm across channels\n",
    "        \n",
    "        im = ax.imshow(pert_magnitude, cmap='hot', vmin=0)\n",
    "        ax.set_title(f'Perturbation\\n(√É‚Äî10 amplified)', fontsize=10, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Magnitude', fontsize=8)\n",
    "    \n",
    "    # Main title\n",
    "    fig.suptitle('Adversarial Attack Comparison on ISIC 2018 Dermoscopy Images\\n'\n",
    "                 '(Green border = Correct prediction, Red border = Misclassification)',\n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_phd_perturbation_analysis(model, images, labels, attacks_dict, num_samples=4):\n",
    "    \"\"\"\n",
    "    Create detailed perturbation analysis figure for dissertation.\n",
    "    Shows spatial distribution and frequency analysis of perturbations.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    images = images[:num_samples].to(device)\n",
    "    labels = labels[:num_samples].to(device)\n",
    "    \n",
    "    # Generate perturbations\n",
    "    perturbations = {}\n",
    "    for name, attack in attacks_dict.items():\n",
    "        adv_imgs = attack(model, images, labels)\n",
    "        perturbations[name] = (adv_imgs - images).cpu()\n",
    "    \n",
    "    # Create figure\n",
    "    num_attacks = len(attacks_dict)\n",
    "    fig, axes = plt.subplots(num_samples, num_attacks * 2 + 1, \n",
    "                             figsize=(3*(num_attacks*2+1), 3.5*num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        ax = axes[i, 0]\n",
    "        clean_img = denormalize_image(images[i].cpu()).permute(1, 2, 0).numpy()\n",
    "        ax.imshow(clean_img)\n",
    "        ax.set_title('Original' if i == 0 else '', fontsize=11, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        col = 1\n",
    "        for name, pert in perturbations.items():\n",
    "            # Spatial perturbation (amplified)\n",
    "            ax = axes[i, col]\n",
    "            pert_spatial = pert[i] * 20  # Amplify 20x\n",
    "            pert_spatial = (pert_spatial - pert_spatial.min()) / (pert_spatial.max() - pert_spatial.min() + 1e-8)\n",
    "            ax.imshow(pert_spatial.permute(1, 2, 0).numpy())\n",
    "            if i == 0:\n",
    "                ax.set_title(f'{name}\\n(Spatial √É‚Äî20)', fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Magnitude heatmap\n",
    "            ax = axes[i, col + 1]\n",
    "            magnitude = pert[i].abs().mean(dim=0).numpy()\n",
    "            im = ax.imshow(magnitude, cmap='inferno')\n",
    "            if i == 0:\n",
    "                ax.set_title(f'{name}\\n(Magnitude)', fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            col += 2\n",
    "    \n",
    "    fig.suptitle('Perturbation Analysis: Spatial Distribution and Magnitude Heatmaps\\n'\n",
    "                 'Revealing Attack Strategies on Medical Dermoscopy Images',\n",
    "                 fontsize=14, fontweight='bold', y=1.02)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_phd_robustness_curves(aggregated_results, config):\n",
    "    \"\"\"\n",
    "    Create publication-quality robustness curves for dissertation.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    epsilons = config['epsilons']\n",
    "    eps_labels = [f'{e*255:.0f}/255' for e in epsilons]\n",
    "    eps_values = [e * 255 for e in epsilons]\n",
    "    \n",
    "    # 1. Robustness vs Epsilon (Line plot)\n",
    "    ax = axes[0, 0]\n",
    "    \n",
    "    # FGSM\n",
    "    fgsm_accs = [aggregated_results['FGSM'][eps]['robust_accuracy']['mean'] for eps in epsilons]\n",
    "    fgsm_stds = [aggregated_results['FGSM'][eps]['robust_accuracy']['std'] for eps in epsilons]\n",
    "    ax.errorbar(eps_values, fgsm_accs, yerr=fgsm_stds, marker='o', markersize=10,\n",
    "                linewidth=2.5, capsize=6, label='FGSM', color=COLORS['fgsm'])\n",
    "    \n",
    "    # PGD-7\n",
    "    pgd7_accs = [aggregated_results['PGD'][f'eps{eps}_steps7']['robust_accuracy']['mean'] for eps in epsilons]\n",
    "    pgd7_stds = [aggregated_results['PGD'][f'eps{eps}_steps7']['robust_accuracy']['std'] for eps in epsilons]\n",
    "    ax.errorbar(eps_values, pgd7_accs, yerr=pgd7_stds, marker='s', markersize=10,\n",
    "                linewidth=2.5, capsize=6, label='PGD-7', color='#3498db')\n",
    "    \n",
    "    # PGD-20\n",
    "    pgd20_accs = [aggregated_results['PGD'][f'eps{eps}_steps20']['robust_accuracy']['mean'] for eps in epsilons]\n",
    "    pgd20_stds = [aggregated_results['PGD'][f'eps{eps}_steps20']['robust_accuracy']['std'] for eps in epsilons]\n",
    "    ax.errorbar(eps_values, pgd20_accs, yerr=pgd20_stds, marker='^', markersize=10,\n",
    "                linewidth=2.5, capsize=6, label='PGD-20', color=COLORS['pgd'])\n",
    "    \n",
    "    ax.axhline(y=100/7, color='gray', linestyle='--', linewidth=1.5, label='Random (14.3%)')\n",
    "    ax.set_xlabel('Perturbation Budget (√é¬µ/255)', fontsize=13)\n",
    "    ax.set_ylabel('Robust Accuracy (%)', fontsize=13)\n",
    "    ax.set_title('(a) Robustness vs Perturbation Budget', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=11)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Attack Comparison Bar Chart\n",
    "    ax = axes[0, 1]\n",
    "    \n",
    "    attacks = ['FGSM\\n√é¬µ=8/255', 'PGD-7\\n√é¬µ=8/255', 'PGD-20\\n√é¬µ=8/255', 'C&W\\nL√¢‚Äö‚Äö']\n",
    "    accs = [\n",
    "        aggregated_results['FGSM'][8/255]['robust_accuracy']['mean'],\n",
    "        aggregated_results['PGD'][f'eps{8/255}_steps7']['robust_accuracy']['mean'],\n",
    "        aggregated_results['PGD'][f'eps{8/255}_steps20']['robust_accuracy']['mean'],\n",
    "        aggregated_results['CW']['robust_accuracy']['mean']\n",
    "    ]\n",
    "    stds = [\n",
    "        aggregated_results['FGSM'][8/255]['robust_accuracy']['std'],\n",
    "        aggregated_results['PGD'][f'eps{8/255}_steps7']['robust_accuracy']['std'],\n",
    "        aggregated_results['PGD'][f'eps{8/255}_steps20']['robust_accuracy']['std'],\n",
    "        aggregated_results['CW']['robust_accuracy']['std']\n",
    "    ]\n",
    "    \n",
    "    colors = [COLORS['fgsm'], '#3498db', COLORS['pgd'], COLORS['cw']]\n",
    "    bars = ax.bar(attacks, accs, yerr=stds, capsize=8, color=colors, \n",
    "                  edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, acc, std in zip(bars, accs, stds):\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{acc:.1f}√Ç¬±{std:.1f}%',\n",
    "                   xy=(bar.get_x() + bar.get_width()/2, height + std + 1),\n",
    "                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.axhline(y=100/7, color='gray', linestyle='--', linewidth=1.5)\n",
    "    ax.set_ylabel('Robust Accuracy (%)', fontsize=13)\n",
    "    ax.set_title('(b) Attack Comparison (Strongest Settings)', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylim(0, max(accs) + 20)\n",
    "    \n",
    "    # 3. Accuracy Drop Heatmap\n",
    "    ax = axes[1, 0]\n",
    "    \n",
    "    # Create matrix for heatmap\n",
    "    steps = [7, 10, 20]\n",
    "    drop_matrix = np.zeros((len(epsilons), len(steps)))\n",
    "    \n",
    "    for i, eps in enumerate(epsilons):\n",
    "        for j, step in enumerate(steps):\n",
    "            drop_matrix[i, j] = aggregated_results['PGD'][f'eps{eps}_steps{step}']['accuracy_drop']['mean']\n",
    "    \n",
    "    im = ax.imshow(drop_matrix, cmap='Reds', aspect='auto')\n",
    "    ax.set_xticks(range(len(steps)))\n",
    "    ax.set_xticklabels([f'{s} steps' for s in steps])\n",
    "    ax.set_yticks(range(len(epsilons)))\n",
    "    ax.set_yticklabels(eps_labels)\n",
    "    ax.set_xlabel('PGD Iterations', fontsize=13)\n",
    "    ax.set_ylabel('Perturbation Budget (√é¬µ)', fontsize=13)\n",
    "    ax.set_title('(c) Accuracy Drop (pp) - PGD Attack', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add annotations\n",
    "    for i in range(len(epsilons)):\n",
    "        for j in range(len(steps)):\n",
    "            ax.text(j, i, f'{drop_matrix[i,j]:.1f}', ha='center', va='center',\n",
    "                   fontsize=12, fontweight='bold', color='white' if drop_matrix[i,j] > 40 else 'black')\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Accuracy Drop (pp)', fontsize=11)\n",
    "    \n",
    "    # 4. Attack Success Rate\n",
    "    ax = axes[1, 1]\n",
    "    \n",
    "    # Success rates for different attacks\n",
    "    categories = ['√é¬µ=2/255', '√é¬µ=4/255', '√é¬µ=8/255']\n",
    "    fgsm_sr = [aggregated_results['FGSM'][eps]['attack_success_rate']['mean'] for eps in epsilons]\n",
    "    pgd_sr = [aggregated_results['PGD'][f'eps{eps}_steps20']['attack_success_rate']['mean'] for eps in epsilons]\n",
    "    \n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, fgsm_sr, width, label='FGSM', color=COLORS['fgsm'], \n",
    "                   edgecolor='black', linewidth=1.5)\n",
    "    bars2 = ax.bar(x + width/2, pgd_sr, width, label='PGD-20', color=COLORS['pgd'],\n",
    "                   edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax.set_ylabel('Attack Success Rate (%)', fontsize=13)\n",
    "    ax.set_xlabel('Perturbation Budget', fontsize=13)\n",
    "    ax.set_title('(d) Attack Success Rate Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.0f}%', xy=(bar.get_x() + bar.get_width()/2, height + 1),\n",
    "                       ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.suptitle('Baseline Model Adversarial Robustness Analysis\\n'\n",
    "                 'ResNet-50 on ISIC 2018 Dermoscopy Dataset (3 Seeds)', \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "print(\"√¢≈ì‚Ä¶ PhD-level visualization functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928ecaf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD MODEL FOR VISUALIZATION\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING MODEL FOR VISUALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load model (use seed 42)\n",
    "vis_checkpoint = f\"{CONFIG['checkpoint_dir']}/seed_42/best.pt\"\n",
    "vis_model = load_model_and_checkpoint(\n",
    "    checkpoint_path=vis_checkpoint,\n",
    "    model_name=CONFIG['model_name'],\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "# Get a batch of test images for visualization\n",
    "vis_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Handle (images, labels, meta) format from ISICDataset\n",
    "batch_data = next(iter(vis_dataloader))\n",
    "if len(batch_data) == 2:\n",
    "    vis_images, vis_labels = batch_data\n",
    "else:\n",
    "    vis_images, vis_labels, _ = batch_data  # Ignore metadata\n",
    "\n",
    "print(f\"‚úÖ Loaded {vis_images.size(0)} images for visualization\")\n",
    "print(f\"   Labels: {vis_labels.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd84c270",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CREATE ATTACKS FOR VISUALIZATION\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"CREATING ATTACKS FOR VISUALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create config objects for each attack\n",
    "vis_fgsm_config = FGSMConfig(\n",
    "    epsilon=0.03,\n",
    "    clip_min=0.0,\n",
    "    clip_max=1.0,\n",
    "    targeted=False\n",
    ")\n",
    "\n",
    "vis_pgd_config = PGDConfig(\n",
    "    epsilon=0.03,\n",
    "    num_steps=20,\n",
    "    step_size=0.03/4,\n",
    "    random_start=True,\n",
    "    clip_min=0.0,\n",
    "    clip_max=1.0,\n",
    "    targeted=False\n",
    ")\n",
    "\n",
    "vis_cw_config = CWConfig(\n",
    "    confidence=0,\n",
    "    learning_rate=CONFIG['cw_lr'],\n",
    "    max_iterations=50,  # Reduced for faster visualization\n",
    "    binary_search_steps=5,\n",
    "    initial_c=CONFIG['cw_c'],\n",
    "    abort_early=True,\n",
    "    clip_min=0.0,\n",
    "    clip_max=1.0\n",
    ")\n",
    "\n",
    "vis_attacks = {\n",
    "    'FGSM (Œµ=0.03)': FGSM(vis_fgsm_config),\n",
    "    'PGD-20 (Œµ=0.03)': PGD(vis_pgd_config),\n",
    "    'C&W': CarliniWagner(vis_cw_config)\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Visualization attacks created:\")\n",
    "for name in vis_attacks:\n",
    "    print(f\"   - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb40e04",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GENERATE ADVERSARIAL VISUALIZATIONS\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"GENERATING ADVERSARIAL VISUALIZATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create results directory\n",
    "results_dir = \"/content/drive/MyDrive/results/phase4_adversarial\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Generate adversarial figure\n",
    "fig = create_phd_adversarial_figure(\n",
    "    model=vis_model,\n",
    "    images=vis_images,\n",
    "    labels=vis_labels,\n",
    "    attacks_dict=vis_attacks,\n",
    "    class_names=CONFIG['class_names'],\n",
    "    num_samples=5\n",
    ")\n",
    "\n",
    "# Save figure\n",
    "vis_save_path = f\"{results_dir}/adversarial_examples_visualization.png\"\n",
    "fig.savefig(vis_save_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"‚úÖ Visualization saved to: {vis_save_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29395203",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PERTURBATION VISUALIZATION\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"GENERATING PERTURBATION VISUALIZATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Generate adversarial examples for all attacks\n",
    "print(\"   Generating adversarial examples...\")\n",
    "adv_examples_dict = {}\n",
    "for attack_name, attack in vis_attacks.items():\n",
    "    print(f\"      - {attack_name}\")\n",
    "    adv_examples_dict[attack_name] = attack(\n",
    "        vis_model, \n",
    "        vis_images.to(CONFIG['device']), \n",
    "        vis_labels.to(CONFIG['device'])\n",
    "    )\n",
    "print(\"   ‚úÖ Adversarial examples generated\")\n",
    "\n",
    "# Create perturbation analysis figure\n",
    "print(\"   Creating perturbation analysis figure...\")\n",
    "fig = create_phd_perturbation_analysis(\n",
    "    model=vis_model,\n",
    "    images=vis_images,\n",
    "    labels=vis_labels,\n",
    "    attacks_dict=vis_attacks,\n",
    "    num_samples=4\n",
    ")\n",
    "\n",
    "# Save\n",
    "pert_save_path = f\"{results_dir}/perturbation_analysis.png\"\n",
    "fig.savefig(pert_save_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"‚úÖ Perturbation analysis saved to: {pert_save_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75cf966",
   "metadata": {},
   "source": [
    "# Section 8: Results Summary and Comparison\n",
    "\n",
    "**Create comparison plots and final summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da95e4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ROBUSTNESS CURVES - PhD Quality Visualization\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"GENERATING ROBUSTNESS CURVES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ============================================================================\n",
    "# Plot 1: Robust accuracy vs epsilon (FGSM and PGD)\n",
    "# ============================================================================\n",
    "epsilons_plot = [e*255 for e in CONFIG['epsilons']]\n",
    "\n",
    "# FGSM accuracies\n",
    "fgsm_accs = [np.mean([r['robust_accuracy'] for r in all_results['FGSM'][eps]]) for eps in CONFIG['epsilons']]\n",
    "fgsm_stds = [np.std([r['robust_accuracy'] for r in all_results['FGSM'][eps]]) for eps in CONFIG['epsilons']]\n",
    "\n",
    "# PGD-20 accuracies\n",
    "pgd_accs = []\n",
    "pgd_stds = []\n",
    "for eps in CONFIG['epsilons']:\n",
    "    key = f\"eps{eps}_steps20\"\n",
    "    results = all_results['PGD'][key]\n",
    "    pgd_accs.append(np.mean([r['robust_accuracy'] for r in results]))\n",
    "    pgd_stds.append(np.std([r['robust_accuracy'] for r in results]))\n",
    "\n",
    "# Clean accuracy baseline\n",
    "clean_acc_mean = np.mean([r['accuracy'] for r in all_results['clean']])\n",
    "\n",
    "axes[0].axhline(y=clean_acc_mean, color='green', linestyle='-', linewidth=2, \n",
    "                label=f'Clean ({clean_acc_mean:.1f}%)', alpha=0.7)\n",
    "axes[0].errorbar(epsilons_plot, fgsm_accs, yerr=fgsm_stds, marker='o', linewidth=2, \n",
    "                 capsize=5, label='FGSM', markersize=8, color=COLORS['fgsm'])\n",
    "axes[0].errorbar(epsilons_plot, pgd_accs, yerr=pgd_stds, marker='s', linewidth=2, \n",
    "                 capsize=5, label='PGD-20', markersize=8, color=COLORS['pgd'])\n",
    "axes[0].axhline(y=100/CONFIG['num_classes'], color='gray', linestyle='--', \n",
    "                label=f'Random ({100/CONFIG[\"num_classes\"]:.1f}%)', alpha=0.5)\n",
    "\n",
    "axes[0].set_xlabel('Perturbation Budget (Œµ √ó 255)', fontsize=13)\n",
    "axes[0].set_ylabel('Robust Accuracy (%)', fontsize=13)\n",
    "axes[0].set_title('Robustness vs Perturbation Budget', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11, loc='upper right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim(0, 100)\n",
    "\n",
    "# ============================================================================\n",
    "# Plot 2: Attack comparison bar chart\n",
    "# ============================================================================\n",
    "attack_names = ['FGSM\\nŒµ=0.03', 'PGD-20\\nŒµ=0.03', 'PGD-40\\nŒµ=0.03', 'C&W']\n",
    "attack_accs = []\n",
    "attack_stds = []\n",
    "\n",
    "# FGSM Œµ=0.03\n",
    "results = all_results['FGSM'][0.03]\n",
    "attack_accs.append(np.mean([r['robust_accuracy'] for r in results]))\n",
    "attack_stds.append(np.std([r['robust_accuracy'] for r in results]))\n",
    "\n",
    "# PGD-20 Œµ=0.03\n",
    "results = all_results['PGD']['eps0.03_steps20']\n",
    "attack_accs.append(np.mean([r['robust_accuracy'] for r in results]))\n",
    "attack_stds.append(np.std([r['robust_accuracy'] for r in results]))\n",
    "\n",
    "# PGD-40 Œµ=0.03\n",
    "results = all_results['PGD']['eps0.03_steps40']\n",
    "attack_accs.append(np.mean([r['robust_accuracy'] for r in results]))\n",
    "attack_stds.append(np.std([r['robust_accuracy'] for r in results]))\n",
    "\n",
    "# C&W\n",
    "results = all_results['CW']\n",
    "attack_accs.append(np.mean([r['robust_accuracy'] for r in results]))\n",
    "attack_stds.append(np.std([r['robust_accuracy'] for r in results]))\n",
    "\n",
    "colors = [COLORS['fgsm'], COLORS['pgd'], '#6c3483', COLORS['cw']]\n",
    "bars = axes[1].bar(attack_names, attack_accs, yerr=attack_stds, \n",
    "                   color=colors, alpha=0.8, capsize=8, width=0.6, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, attack_accs):\n",
    "    height = bar.get_height()\n",
    "    axes[1].annotate(f'{acc:.1f}%', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                    xytext=(0, 5), textcoords='offset points',\n",
    "                    ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "axes[1].axhline(y=clean_acc_mean, color='green', linestyle='-', linewidth=2, \n",
    "                label=f'Clean ({clean_acc_mean:.1f}%)', alpha=0.7)\n",
    "axes[1].axhline(y=100/CONFIG['num_classes'], color='gray', linestyle='--', \n",
    "                label=f'Random ({100/CONFIG[\"num_classes\"]:.1f}%)', alpha=0.5)\n",
    "\n",
    "axes[1].set_ylabel('Robust Accuracy (%)', fontsize=13)\n",
    "axes[1].set_title('Attack Comparison (Œµ=0.03)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim(0, max(attack_accs) + 20)\n",
    "axes[1].legend(fontsize=11, loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.suptitle('Baseline ResNet-50 Adversarial Robustness on ISIC 2018\\n(Mean ¬± Std across 3 seeds)', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# Save\n",
    "curves_save_path = f\"{results_dir}/robustness_curves.png\"\n",
    "fig.savefig(curves_save_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"‚úÖ Robustness curves saved to: {curves_save_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5d366",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL SUMMARY REPORT\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE 4 - BASELINE ROBUSTNESS EVALUATION - FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract key results\n",
    "clean_acc_mean = np.mean([r['accuracy'] for r in all_results['clean']])\n",
    "clean_acc_std = np.std([r['accuracy'] for r in all_results['clean']])\n",
    "\n",
    "# FGSM Œµ=0.03 results\n",
    "fgsm_results = all_results['FGSM'][0.03]\n",
    "fgsm_robust_mean = np.mean([r['robust_accuracy'] for r in fgsm_results])\n",
    "fgsm_robust_std = np.std([r['robust_accuracy'] for r in fgsm_results])\n",
    "fgsm_drop_mean = np.mean([r['accuracy_drop'] for r in fgsm_results])\n",
    "fgsm_success_mean = np.mean([r['attack_success_rate'] for r in fgsm_results])\n",
    "\n",
    "# PGD-20 Œµ=0.03 results\n",
    "pgd_results = all_results['PGD']['eps0.03_steps20']\n",
    "pgd_robust_mean = np.mean([r['robust_accuracy'] for r in pgd_results])\n",
    "pgd_robust_std = np.std([r['robust_accuracy'] for r in pgd_results])\n",
    "pgd_drop_mean = np.mean([r['accuracy_drop'] for r in pgd_results])\n",
    "pgd_success_mean = np.mean([r['attack_success_rate'] for r in pgd_results])\n",
    "\n",
    "# C&W results\n",
    "cw_results = all_results['CW']\n",
    "cw_robust_mean = np.mean([r['robust_accuracy'] for r in cw_results])\n",
    "cw_robust_std = np.std([r['robust_accuracy'] for r in cw_results])\n",
    "cw_drop_mean = np.mean([r['accuracy_drop'] for r in cw_results])\n",
    "cw_l2_mean = np.mean([r['mean_l2_dist'] for r in cw_results])\n",
    "\n",
    "print(\"\\nüìã KEY FINDINGS:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(f\"\\n1. BASELINE CLEAN ACCURACY:\")\n",
    "print(f\"   {clean_acc_mean:.2f}% ¬± {clean_acc_std:.2f}%\")\n",
    "\n",
    "print(f\"\\n2. FGSM ATTACK (Œµ=0.03):\")\n",
    "print(f\"   Robust Accuracy: {fgsm_robust_mean:.2f}% ¬± {fgsm_robust_std:.2f}%\")\n",
    "print(f\"   Accuracy Drop: {fgsm_drop_mean:.2f}pp\")\n",
    "print(f\"   Attack Success Rate: {fgsm_success_mean:.2f}%\")\n",
    "\n",
    "print(f\"\\n3. PGD-20 ATTACK (Œµ=0.03):\")\n",
    "print(f\"   Robust Accuracy: {pgd_robust_mean:.2f}% ¬± {pgd_robust_std:.2f}%\")\n",
    "print(f\"   Accuracy Drop: {pgd_drop_mean:.2f}pp\")\n",
    "print(f\"   Attack Success Rate: {pgd_success_mean:.2f}%\")\n",
    "\n",
    "print(f\"\\n4. CARLINI & WAGNER ATTACK:\")\n",
    "print(f\"   Robust Accuracy: {cw_robust_mean:.2f}% ¬± {cw_robust_std:.2f}%\")\n",
    "print(f\"   Accuracy Drop: {cw_drop_mean:.2f}pp\")\n",
    "print(f\"   Mean L2 Distance: {cw_l2_mean:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PHASE 4.3 CHECKLIST VERIFICATION:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"‚úÖ All attacks implemented and tested (FGSM, PGD, C&W)\")\n",
    "print(\"‚úÖ Baseline robustness evaluated across 3 seeds\")\n",
    "print(f\"‚úÖ Accuracy drop verified: {pgd_drop_mean:.1f}pp under PGD-20\")\n",
    "print(\"‚úÖ Statistical aggregation completed (mean ¬± std)\")\n",
    "print(\"‚úÖ Adversarial examples visualized\")\n",
    "print(f\"‚úÖ Results saved to: {results_dir}\")\n",
    "\n",
    "print(\"\\nüéØ CONCLUSION:\")\n",
    "if pgd_drop_mean >= 30:\n",
    "    print(\"   ‚úÖ Baseline model shows SIGNIFICANT VULNERABILITY to adversarial attacks\")\n",
    "    print(\"   ‚úÖ This validates the need for robust training in Phase 5\")\n",
    "    print(\"   ‚úÖ Ready to proceed with Tri-Objective Robust XAI Training\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Baseline model shows some robustness\")\n",
    "    print(\"   ‚ÑπÔ∏è  Consider stronger attack parameters for evaluation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéì DISSERTATION TAKEAWAY:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"   The baseline ResNet-50 achieves {clean_acc_mean:.1f}% clean accuracy on ISIC 2018,\")\n",
    "print(f\"   but drops to only {pgd_robust_mean:.1f}% under PGD-20 attack (Œµ=0.03).\")\n",
    "print(f\"   This {pgd_drop_mean:.1f}pp accuracy drop demonstrates the critical need\")\n",
    "print(\"   for adversarially robust training in medical imaging applications.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0430ddc4",
   "metadata": {},
   "source": [
    "# Section 9: Phase 4.4 - Attack Transferability (Optional)\n",
    "\n",
    "**Test adversarial transferability across different model architectures**\n",
    "\n",
    "√¢≈°¬†√Ø¬∏¬è **Note:** This section requires checkpoints from different architectures (e.g., EfficientNet, DenseNet).\n",
    "If not available, skip this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cec390",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Transferability study (optional - requires additional model checkpoints)\n",
    "# Uncomment and run if you have checkpoints from other architectures\n",
    "\n",
    "\"\"\"\n",
    "# Example: Test transferability from ResNet-50 to EfficientNet\n",
    "\n",
    "# Load target model (EfficientNet)\n",
    "target_checkpoint = \"/content/drive/MyDrive/checkpoints/efficientnet/seed_42/best.pt\"\n",
    "target_model = load_model_and_checkpoint(\n",
    "    checkpoint_path=target_checkpoint,\n",
    "    model_name=\"efficientnet_b0\",\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "# Generate adversarials on source model (ResNet-50)\n",
    "source_model = vis_model  # Already loaded ResNet-50\n",
    "\n",
    "# Get test batch\n",
    "transfer_images, transfer_labels = next(iter(test_loader))\n",
    "transfer_images = transfer_images.to(CONFIG['device'])\n",
    "transfer_labels = transfer_labels.to(CONFIG['device'])\n",
    "\n",
    "# Generate adversarials with PGD on ResNet-50\n",
    "pgd_transfer = PGD(\n",
    "    epsilon=8/255,\n",
    "    alpha=2/255,\n",
    "    num_steps=20,\n",
    "    random_start=True,\n",
    "    clip_min=0.0,\n",
    "    clip_max=1.0,\n",
    "    targeted=False\n",
    ")\n",
    "\n",
    "adv_images_transfer = pgd_transfer(source_model, transfer_images, transfer_labels)\n",
    "\n",
    "# Evaluate on source model\n",
    "with torch.no_grad():\n",
    "    source_clean_logits = source_model(transfer_images)\n",
    "    source_adv_logits = source_model(adv_images_transfer)\n",
    "    \n",
    "    source_clean_acc = (source_clean_logits.argmax(1) == transfer_labels).float().mean().item() * 100\n",
    "    source_adv_acc = (source_adv_logits.argmax(1) == transfer_labels).float().mean().item() * 100\n",
    "\n",
    "# Evaluate on target model\n",
    "with torch.no_grad():\n",
    "    target_clean_logits = target_model(transfer_images)\n",
    "    target_adv_logits = target_model(adv_images_transfer)\n",
    "    \n",
    "    target_clean_acc = (target_clean_logits.argmax(1) == transfer_labels).float().mean().item() * 100\n",
    "    target_adv_acc = (target_adv_logits.argmax(1) == transfer_labels).float().mean().item() * 100\n",
    "\n",
    "# Compute transferability rate\n",
    "transfer_rate = (source_clean_acc - target_adv_acc) / (source_clean_acc - source_adv_acc) * 100\n",
    "\n",
    "print(f\"Source Model (ResNet-50):\")\n",
    "print(f\"  Clean Accuracy: {source_clean_acc:.2f}%\")\n",
    "print(f\"  Adversarial Accuracy: {source_adv_acc:.2f}%\")\n",
    "print(f\"  Accuracy Drop: {source_clean_acc - source_adv_acc:.2f}pp\")\n",
    "\n",
    "print(f\"\\nTarget Model (EfficientNet):\")\n",
    "print(f\"  Clean Accuracy: {target_clean_acc:.2f}%\")\n",
    "print(f\"  Adversarial Accuracy (transferred): {target_adv_acc:.2f}%\")\n",
    "print(f\"  Accuracy Drop: {target_clean_acc - target_adv_acc:.2f}pp\")\n",
    "\n",
    "print(f\"\\nTransferability Rate: {transfer_rate:.2f}%\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"√¢≈°¬†√Ø¬∏¬è  Transferability study skipped - requires additional model checkpoints\")\n",
    "print(\"   To enable, uncomment the code above and provide checkpoints from different architectures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cba73f",
   "metadata": {},
   "source": [
    "# √∞≈∏≈Ω‚Ä∞ Phase 4 Execution Complete!\n",
    "\n",
    "---\n",
    "\n",
    "## √¢≈ì‚Ä¶ Completed Tasks\n",
    "\n",
    "### Phase 4.3: Baseline Robustness Evaluation\n",
    "- √¢≈ì‚Ä¶ Evaluated FGSM attack (3 epsilons √É‚Äî 3 seeds = 9 experiments)\n",
    "- √¢≈ì‚Ä¶ Evaluated PGD attack (3 epsilons √É‚Äî 3 steps √É‚Äî 3 seeds = 27 experiments)\n",
    "- √¢≈ì‚Ä¶ Evaluated C&W attack (3 seeds)\n",
    "- √¢≈ì‚Ä¶ Statistical aggregation (mean √Ç¬± std)\n",
    "- √¢≈ì‚Ä¶ Results saved to JSON\n",
    "\n",
    "### Phase 4.5: Adversarial Visualization\n",
    "- √¢≈ì‚Ä¶ Generated adversarial example visualizations\n",
    "- √¢≈ì‚Ä¶ Created amplified perturbation visualizations\n",
    "- √¢≈ì‚Ä¶ Comparison plots (robustness vs epsilon, attack comparison)\n",
    "- √¢≈ì‚Ä¶ All figures saved to results directory\n",
    "\n",
    "### Phase 4.4: Attack Transferability\n",
    "- √¢¬è¬≠√Ø¬∏¬è Skipped (requires additional model architectures)\n",
    "\n",
    "---\n",
    "\n",
    "## √∞≈∏‚Äú≈† Expected Outputs\n",
    "\n",
    "All results saved to: `/content/drive/MyDrive/results/robustness/`\n",
    "\n",
    "**Files Generated:**\n",
    "1. `baseline_robustness_aggregated.json` - Statistical results across seeds\n",
    "2. `adversarial_examples_visualization.png` - Clean vs adversarial examples\n",
    "3. `perturbation_visualization.png` - Amplified perturbations\n",
    "4. `attack_comparison.png` - Attack effectiveness comparison\n",
    "\n",
    "---\n",
    "\n",
    "## √∞≈∏≈Ω¬Ø Next Steps\n",
    "\n",
    "1. **Review Results:** Check accuracy drops match expected 50-70pp range\n",
    "2. **Dissertation:** Use generated figures for Phase 4 results chapter\n",
    "3. **Phase 5:** Proceed to tri-objective robust XAI training if baseline vulnerability confirmed\n",
    "4. **Optional:** Run transferability study if you train models with different architectures\n",
    "\n",
    "---\n",
    "\n",
    "## √∞≈∏‚Äú¬ù Citation\n",
    "\n",
    "\n",
    "- FGSM: Goodfellow et al., https://doi.org/10.48550/arXiv.1412.6572  ,\"Explaining and Harnessing Adversarial Examples\" (2015)\n",
    "- PGD: Madry et al., https://openreview.net/forum?id=rJzIBfZAb  ,\"Towards Deep Learning Models Resistant to Adversarial Attacks\" (2018)\n",
    "- C&W: Carlini & Wagner, \n",
    "https://doi.org/10.48550/arXiv.1608.04644\n",
    "   ,\"Towards Evaluating the Robustness of Neural Networks\" (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993c625",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
