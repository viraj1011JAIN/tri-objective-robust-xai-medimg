{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aea92a4",
   "metadata": {},
   "source": [
    "# üöÄ Google Colab Pro Setup Guide\n",
    "# Tri-Objective Robust XAI for Medical Imaging\n",
    "\n",
    "This notebook will help you set up the complete project environment on Google Colab Pro.\n",
    "\n",
    "## üìã Prerequisites\n",
    "1. **Google Colab Pro** subscription (for better GPU access)\n",
    "2. **GitHub repository** up to date: `viraj1011JAIN/tri-objective-robust-xai-medimg`\n",
    "3. **Data zip file** uploaded to Google Drive\n",
    "4. **GPU Runtime** enabled (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
    "\n",
    "## üéØ What This Notebook Does\n",
    "1. Mounts Google Drive\n",
    "2. Clones the GitHub repository\n",
    "3. Extracts your data from Google Drive\n",
    "4. Installs PyTorch with CUDA support\n",
    "5. Installs all project dependencies\n",
    "6. Verifies GPU and environment setup\n",
    "7. Runs quick tests to ensure everything works\n",
    "8. Provides training examples\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Important Notes\n",
    "- **Save checkpoints to Google Drive** regularly to prevent data loss\n",
    "- **Keep session alive** - Colab disconnects after ~90 minutes of inactivity\n",
    "- **Use T4/V100/A100 GPU** for best performance (check Runtime type)\n",
    "- **Update paths** in cells marked with `# TODO` to match your Google Drive structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4c653",
   "metadata": {},
   "source": [
    "## Step 1: Mount Google Drive\n",
    "\n",
    "This will allow access to your data files stored in Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97df8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify mount\n",
    "import os\n",
    "print(\"‚úÖ Google Drive mounted successfully!\")\n",
    "print(f\"üìÅ Drive contents: {os.listdir('/content/drive/MyDrive/')[:10]}\")  # Show first 10 items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa9549",
   "metadata": {},
   "source": [
    "## Step 2: Clone GitHub Repository\n",
    "\n",
    "Clone the project repository from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64616fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/viraj1011JAIN/tri-objective-robust-xai-medimg.git\n",
    "%cd tri-objective-robust-xai-medimg\n",
    "\n",
    "# Verify repository contents\n",
    "!echo \"‚úÖ Repository cloned successfully!\"\n",
    "!echo \"\"\n",
    "!echo \"üìÇ Project structure:\"\n",
    "!ls -la\n",
    "\n",
    "!echo \"\"\n",
    "!echo \"üîç Checking key directories:\"\n",
    "!ls -d src/ tests/ configs/ notebooks/ 2>/dev/null || echo \"Directories found!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e43cd5",
   "metadata": {},
   "source": [
    "## Step 3: Extract Data from Google Drive\n",
    "\n",
    "**üìç TODO: Update the `zip_path` variable to match your Google Drive structure!**\n",
    "\n",
    "Your zip file should contain datasets like ISIC2018, NIH CXR-14, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98de18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# TODO: Update this path to your actual zip file location in Google Drive\n",
    "zip_path = '/content/drive/MyDrive/dissertation_data/medical_imaging_data.zip'\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = Path('./data/raw')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üì¶ Extracting data from: {zip_path}\")\n",
    "print(f\"üìÅ Extracting to: {data_dir}\")\n",
    "print(\"‚è≥ This may take several minutes depending on data size...\")\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Get total file count\n",
    "        file_list = zip_ref.namelist()\n",
    "        total_files = len(file_list)\n",
    "        \n",
    "        print(f\"üìä Total files to extract: {total_files}\")\n",
    "        \n",
    "        # Extract all files\n",
    "        zip_ref.extractall(data_dir)\n",
    "        \n",
    "    print(\"‚úÖ Data extracted successfully!\")\n",
    "    print(\"\\nüìÇ Extracted contents:\")\n",
    "    !ls -lh ./data/raw/\n",
    "    \n",
    "    # Check for expected datasets\n",
    "    print(\"\\nüîç Checking for expected datasets:\")\n",
    "    expected_datasets = ['isic2018', 'nih_cxr14', 'derm7pt']\n",
    "    for dataset in expected_datasets:\n",
    "        dataset_path = data_dir / dataset\n",
    "        if dataset_path.exists():\n",
    "            print(f\"  ‚úÖ {dataset} found\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  {dataset} not found (might be named differently)\")\n",
    "            \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: Zip file not found at {zip_path}\")\n",
    "    print(\"Please update the zip_path variable to match your Google Drive structure.\")\n",
    "    print(\"\\nüí° Tip: Check your Google Drive path by running:\")\n",
    "    print(\"!ls -la /content/drive/MyDrive/\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR during extraction: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f191c",
   "metadata": {},
   "source": [
    "## Step 4: Install PyTorch with CUDA Support\n",
    "\n",
    "Installing PyTorch optimized for Colab's CUDA environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA 12.1 support (matches Colab's CUDA version)\n",
    "print(\"üîß Installing PyTorch with CUDA support...\")\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "print(\"\\n‚úÖ PyTorch installed successfully!\")\n",
    "print(f\"üì¶ PyTorch version: {torch.__version__}\")\n",
    "print(f\"üî• CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"üíª GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"üöÄ cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: CUDA not available! Please check Runtime settings:\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí Select GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898a7a8",
   "metadata": {},
   "source": [
    "## Step 5: Install Project Dependencies\n",
    "\n",
    "Installing all required packages from `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c67b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Installing project dependencies...\")\n",
    "print(\"‚è≥ This may take 2-3 minutes...\\n\")\n",
    "\n",
    "# Install requirements\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Install project in editable mode\n",
    "!pip install -q -e .\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed successfully!\")\n",
    "\n",
    "# Show installed packages (key ones)\n",
    "print(\"\\nüì¶ Key installed packages:\")\n",
    "!pip list | grep -E \"(torch|numpy|pandas|scikit|pillow|albumentations|timm|pydantic|mlflow)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5341fe",
   "metadata": {},
   "source": [
    "## Step 6: Verify Project Setup\n",
    "\n",
    "Test that all project modules can be imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Verifying project imports...\\n\")\n",
    "\n",
    "# Test imports from all major modules\n",
    "try:\n",
    "    # Losses\n",
    "    from src.losses.robust_loss import TRADESLoss, MARTLoss, AdversarialTrainingLoss\n",
    "    print(\"‚úÖ Robust losses imported successfully\")\n",
    "    \n",
    "    # Training\n",
    "    from src.training.adversarial_trainer import AdversarialTrainer, train_adversarial_epoch, validate_robust\n",
    "    print(\"‚úÖ Adversarial trainer imported successfully\")\n",
    "    \n",
    "    # Attacks\n",
    "    from src.attacks import PGD, FGSM, CW, AutoAttack\n",
    "    from src.attacks.pgd import PGDConfig\n",
    "    print(\"‚úÖ Attack modules imported successfully\")\n",
    "    \n",
    "    # Models\n",
    "    from src.models import build_model\n",
    "    from src.models.resnet import ResNet\n",
    "    print(\"‚úÖ Model modules imported successfully\")\n",
    "    \n",
    "    # Datasets\n",
    "    from src.datasets import ISICDataset, ChestXRayDataset\n",
    "    print(\"‚úÖ Dataset modules imported successfully\")\n",
    "    \n",
    "    # Utils\n",
    "    from src.utils.config import load_experiment_config\n",
    "    from src.utils.reproducibility import set_seed\n",
    "    print(\"‚úÖ Utility modules imported successfully\")\n",
    "    \n",
    "    print(\"\\nüéâ All imports successful! Environment is ready.\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {str(e)}\")\n",
    "    print(\"Please check that all installation steps completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75c003",
   "metadata": {},
   "source": [
    "## Step 7: Run Quick Tests\n",
    "\n",
    "Run a subset of tests to ensure Phase 5.1 (Adversarial Training) works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ Running quick tests...\\n\")\n",
    "\n",
    "# Run Phase 5.1 adversarial training tests\n",
    "!pytest tests/test_adversarial_training.py::TestTRADESLoss -v --tb=short --disable-warnings\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Test Summary:\")\n",
    "print(\"=\"*70)\n",
    "!pytest tests/test_adversarial_training.py::    TestTRADESLoss -q --disable-warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca243b1b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Training Examples\n",
    "\n",
    "Now you're ready to start training! Choose one of the examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d9a49",
   "metadata": {},
   "source": [
    "### Option 1: Train with TRADES (Recommended)\n",
    "\n",
    "TRADES balances clean accuracy and robust accuracy using KL divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62784d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with TRADES loss on ISIC2018 dataset\n",
    "!python -m src.training.train_baseline \\\n",
    "    --config configs/experiments/adversarial_training_trades_isic.yaml \\\n",
    "    --device cuda \\\n",
    "    --max_epochs 50 \\\n",
    "    --output_dir ./results/trades_isic \\\n",
    "    --checkpoint_dir ./checkpoints/trades_isic\n",
    "\n",
    "# Results will be saved to:\n",
    "# - Checkpoints: ./checkpoints/trades_isic/\n",
    "# - Results: ./results/trades_isic/\n",
    "# - Logs: ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e67e7f",
   "metadata": {},
   "source": [
    "### Option 2: Train with MART\n",
    "\n",
    "MART focuses on misclassified examples for improved robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with MART loss on ISIC2018 dataset\n",
    "!python -m src.training.train_baseline \\\n",
    "    --config configs/experiments/adversarial_training_mart_isic.yaml \\\n",
    "    --device cuda \\\n",
    "    --max_epochs 50 \\\n",
    "    --output_dir ./results/mart_isic \\\n",
    "    --checkpoint_dir ./checkpoints/mart_isic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68db474f",
   "metadata": {},
   "source": [
    "### Option 3: Standard Adversarial Training\n",
    "\n",
    "Pure adversarial training without additional regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c448ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with standard adversarial training on ISIC2018\n",
    "!python -m src.training.train_baseline \\\n",
    "    --config configs/experiments/adversarial_training_standard_isic.yaml \\\n",
    "    --device cuda \\\n",
    "    --max_epochs 50 \\\n",
    "    --output_dir ./results/standard_at_isic \\\n",
    "    --checkpoint_dir ./checkpoints/standard_at_isic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960021cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ Save Results to Google Drive\n",
    "\n",
    "**Important:** Always save your results back to Google Drive to prevent data loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamped backup directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_dir = f'/content/drive/MyDrive/dissertation_results/{timestamp}'\n",
    "\n",
    "print(f\"üíæ Saving results to: {backup_dir}\")\n",
    "print(\"‚è≥ This may take a few minutes...\\n\")\n",
    "\n",
    "# Create backup directory\n",
    "!mkdir -p {backup_dir}\n",
    "\n",
    "# Copy checkpoints\n",
    "if os.path.exists('./checkpoints'):\n",
    "    print(\"üìÇ Copying checkpoints...\")\n",
    "    !cp -r ./checkpoints {backup_dir}/\n",
    "    print(\"‚úÖ Checkpoints saved\")\n",
    "\n",
    "# Copy results\n",
    "if os.path.exists('./results'):\n",
    "    print(\"üìÇ Copying results...\")\n",
    "    !cp -r ./results {backup_dir}/\n",
    "    print(\"‚úÖ Results saved\")\n",
    "\n",
    "# Copy logs\n",
    "if os.path.exists('./logs'):\n",
    "    print(\"üìÇ Copying logs...\")\n",
    "    !cp -r ./logs {backup_dir}/\n",
    "    print(\"‚úÖ Logs saved\")\n",
    "\n",
    "# Copy mlruns (MLflow tracking)\n",
    "if os.path.exists('./mlruns'):\n",
    "    print(\"üìÇ Copying MLflow runs...\")\n",
    "    !cp -r ./mlruns {backup_dir}/\n",
    "    print(\"‚úÖ MLflow runs saved\")\n",
    "\n",
    "print(f\"\\nüéâ All results backed up to Google Drive!\")\n",
    "print(f\"üìÅ Location: {backup_dir}\")\n",
    "print(\"\\nüí° Tip: Download this folder for local analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87358874",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Utility Functions & Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2ed5d",
   "metadata": {},
   "source": [
    "### Keep Session Alive\n",
    "\n",
    "Prevents Colab from disconnecting due to inactivity (useful for long training runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Colab session alive (run this cell to start)\n",
    "import time\n",
    "import threading\n",
    "from IPython.display import display, Javascript\n",
    "\n",
    "def keep_alive():\n",
    "    \"\"\"Keep the Colab session alive by simulating activity.\"\"\"\n",
    "    while True:\n",
    "        display(Javascript('console.log(\"Keeping session alive...\")'))\n",
    "        time.sleep(60)  # Ping every 60 seconds\n",
    "\n",
    "# Start keep-alive thread\n",
    "thread = threading.Thread(target=keep_alive, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "print(\"‚úÖ Keep-alive thread started!\")\n",
    "print(\"üí° Your session will stay active as long as this notebook is open\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc19594",
   "metadata": {},
   "source": [
    "### Monitor GPU Usage\n",
    "\n",
    "Check GPU utilization and memory during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c478b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor GPU usage\n",
    "!nvidia-smi\n",
    "\n",
    "# Detailed GPU info\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\" \" * 25 + \"GPU INFORMATION\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "    print(f\"\\nMemory Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"Memory Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"Max Memory Allocated: {torch.cuda.max_memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"{'='*70}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83822c26",
   "metadata": {},
   "source": [
    "### TensorBoard Integration\n",
    "\n",
    "Monitor training metrics in real-time using TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39eb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard (runs in background)\n",
    "%tensorboard --logdir /content/tri-objective-robust-xai-medimg/logs/\n",
    "\n",
    "# Alternative: Launch TensorBoard for MLflow runs\n",
    "# %tensorboard --logdir /content/tri-objective-robust-xai-medimg/mlruns/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565d4a06",
   "metadata": {},
   "source": [
    "### Resume Training from Checkpoint\n",
    "\n",
    "If your session disconnects, you can resume training from the last checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c5e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume training from last checkpoint\n",
    "# Add --resume flag to your training command\n",
    "\n",
    "# Example 1: Resume TRADES training\n",
    "!python /content/tri-objective-robust-xai-medimg/scripts/train_adversarial.py \\\n",
    "    --config /content/tri-objective-robust-xai-medimg/configs/experiments/adversarial/trades_cifar10.yaml \\\n",
    "    --resume \\\n",
    "    --checkpoint /content/tri-objective-robust-xai-medimg/checkpoints/last.pt\n",
    "\n",
    "# Example 2: Resume from specific checkpoint\n",
    "!python /content/tri-objective-robust-xai-medimg/scripts/train_adversarial.py \\\n",
    "    --config /content/tri-objective-robust-xai-medimg/configs/experiments/adversarial/trades_cifar10.yaml \\\n",
    "    --resume \\\n",
    "    --checkpoint /content/tri-objective-robust-xai-medimg/checkpoints/baseline/epoch_10.pt\n",
    "\n",
    "# Example 3: Resume from Google Drive checkpoint (if you saved it earlier)\n",
    "!python /content/tri-objective-robust-xai-medimg/scripts/train_adversarial.py \\\n",
    "    --config /content/tri-objective-robust-xai-medimg/configs/experiments/adversarial/trades_cifar10.yaml \\\n",
    "    --resume \\\n",
    "    --checkpoint /content/drive/MyDrive/tri_objective_results/checkpoints/last.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c10ed8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Troubleshooting & FAQ\n",
    "\n",
    "### Common Issues and Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0cb892",
   "metadata": {},
   "source": [
    "#### **Issue 1: CUDA Out of Memory**\n",
    "\n",
    "**Error:** `RuntimeError: CUDA out of memory`\n",
    "\n",
    "**Solutions:**\n",
    "- Reduce batch size in config file\n",
    "- Clear GPU cache: `torch.cuda.empty_cache()`\n",
    "- Restart runtime and re-run setup\n",
    "- Use gradient checkpointing (if available)\n",
    "\n",
    "```python\n",
    "# Clear CUDA cache\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "print(\"GPU cache cleared!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288fc88",
   "metadata": {},
   "source": [
    "#### **Issue 2: Data Not Found**\n",
    "\n",
    "**Error:** `FileNotFoundError: [Errno 2] No such file or directory: '/content/tri-objective-robust-xai-medimg/data/...'`\n",
    "\n",
    "**Solutions:**\n",
    "- Check if data extraction completed: `!ls /content/tri-objective-robust-xai-medimg/data/`\n",
    "- Re-run data extraction cell (Step 3)\n",
    "- Verify zip file exists in Google Drive\n",
    "- Check data path in config files\n",
    "\n",
    "```python\n",
    "# Verify data directories\n",
    "import os\n",
    "data_dir = \"/content/tri-objective-robust-xai-medimg/data\"\n",
    "if os.path.exists(data_dir):\n",
    "    print(f\"‚úÖ Data directory exists\")\n",
    "    print(f\"Contents: {os.listdir(data_dir)}\")\n",
    "else:\n",
    "    print(f\"‚ùå Data directory NOT found!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8219eb3",
   "metadata": {},
   "source": [
    "#### **Issue 3: Import Errors**\n",
    "\n",
    "**Error:** `ModuleNotFoundError: No module named 'src'`\n",
    "\n",
    "**Solutions:**\n",
    "- Verify working directory: `!pwd` should show `/content/tri-objective-robust-xai-medimg`\n",
    "- Change directory: `%cd /content/tri-objective-robust-xai-medimg`\n",
    "- Re-run dependency installation (Step 5)\n",
    "- Check PYTHONPATH\n",
    "\n",
    "```python\n",
    "# Fix import paths\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = \"/content/tri-objective-robust-xai-medimg\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"‚úÖ Added {project_root} to PYTHONPATH\")\n",
    "\n",
    "# Verify imports work\n",
    "try:\n",
    "    from src.models.resnet import ResNet18\n",
    "    print(\"‚úÖ Imports working correctly!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba5e5d",
   "metadata": {},
   "source": [
    "#### **Issue 4: Session Disconnects During Training**\n",
    "\n",
    "**Problem:** Long training runs interrupted by Colab disconnection\n",
    "\n",
    "**Solutions:**\n",
    "- Enable keep-alive script (see \"Keep Session Alive\" section above)\n",
    "- Save checkpoints frequently (modify config: `save_freq: 5`)\n",
    "- Save results to Google Drive periodically\n",
    "- Use Colab Pro+ for longer runtimes (24 hours)\n",
    "- Split training into smaller epochs and resume\n",
    "\n",
    "```python\n",
    "# Quick checkpoint backup to Drive\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "checkpoint_dir = \"/content/tri-objective-robust-xai-medimg/checkpoints\"\n",
    "backup_dir = f\"/content/drive/MyDrive/tri_objective_checkpoints/backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    shutil.copytree(checkpoint_dir, backup_dir)\n",
    "    print(f\"‚úÖ Checkpoints backed up to: {backup_dir}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b3764",
   "metadata": {},
   "source": [
    "#### **Issue 5: PyTorch Version Mismatch**\n",
    "\n",
    "**Error:** `RuntimeError: Detected that PyTorch and torchvision were compiled with different CUDA versions`\n",
    "\n",
    "**Solution:** Reinstall PyTorch with correct CUDA version\n",
    "\n",
    "```python\n",
    "# Uninstall existing PyTorch\n",
    "!pip uninstall -y torch torchvision torchaudio\n",
    "\n",
    "# Reinstall with CUDA 12.1 (matches Colab's CUDA version)\n",
    "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dae264",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- **GitHub Repository:** [viraj1011JAIN/tri-objective-robust-xai-medimg](https://github.com/viraj1011JAIN/tri-objective-robust-xai-medimg)\n",
    "- **Documentation:** See `docs/` folder in repository\n",
    "- **Phase Reports:** Check `PHASE_*.md` files for detailed implementation guides\n",
    "\n",
    "### Quick Commands Reference\n",
    "\n",
    "```bash\n",
    "# Check GPU\n",
    "nvidia-smi\n",
    "\n",
    "# Run tests\n",
    "pytest tests/ -v\n",
    "\n",
    "# Train with TRADES\n",
    "python scripts/train_adversarial.py --config configs/experiments/adversarial/trades_cifar10.yaml\n",
    "\n",
    "# Monitor with TensorBoard\n",
    "tensorboard --logdir logs/ --port 6006\n",
    "\n",
    "# Clear CUDA cache\n",
    "python -c \"import torch; torch.cuda.empty_cache(); print('Cache cleared')\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Completion Checklist\n",
    "\n",
    "Before starting training, verify:\n",
    "\n",
    "- [ ] Google Drive mounted successfully\n",
    "- [ ] Repository cloned to `/content/tri-objective-robust-xai-medimg`\n",
    "- [ ] Data extracted to `data/` directory\n",
    "- [ ] PyTorch with CUDA 12.1 installed\n",
    "- [ ] All dependencies installed (`pip install -r requirements.txt`)\n",
    "- [ ] Import test passed\n",
    "- [ ] Quick test suite passed\n",
    "- [ ] GPU detected and available\n",
    "- [ ] Keep-alive script running (optional, for long training)\n",
    "\n",
    "**Ready to train! üöÄ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42356c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with MART loss on ISIC2018 dataset\n",
    "!python -m src.training.train_baseline \\\n",
    "    --config configs/experiments/adversarial_training_mart_isic.yaml \\\n",
    "    --device cuda \\\n",
    "    --max_epochs 50 \\\n",
    "    --output_dir ./results/mart_isic \\\n",
    "    --checkpoint_dir ./checkpoints/mart_isic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb5a4f",
   "metadata": {},
   "source": [
    "### Option 3: Standard Adversarial Training\n",
    "\n",
    "Pure adversarial training without additional regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad883027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with standard adversarial training on ISIC2018\n",
    "!python -m src.training.train_baseline \\\n",
    "    --config configs/experiments/adversarial_training_standard_isic.yaml \\\n",
    "    --device cuda \\\n",
    "    --max_epochs 50 \\\n",
    "    --output_dir ./results/standard_at_isic \\\n",
    "    --checkpoint_dir ./checkpoints/standard_at_isic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5993f8d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ Save Results to Google Drive\n",
    "\n",
    "**IMPORTANT:** Always save your results back to Google Drive to prevent data loss when Colab session ends!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52344808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamped backup folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_dir = f\"/content/drive/MyDrive/dissertation_results_backup_{timestamp}\"\n",
    "\n",
    "print(f\"üíæ Saving results to: {backup_dir}\\n\")\n",
    "\n",
    "# Create backup directory\n",
    "!mkdir -p \"{backup_dir}\"\n",
    "\n",
    "# Copy checkpoints\n",
    "if os.path.exists('./checkpoints'):\n",
    "    print(\"üì¶ Copying checkpoints...\")\n",
    "    shutil.copytree('./checkpoints', f\"{backup_dir}/checkpoints\", dirs_exist_ok=True)\n",
    "    print(\"‚úÖ Checkpoints saved\")\n",
    "\n",
    "# Copy results\n",
    "if os.path.exists('./results'):\n",
    "    print(\"üìä Copying results...\")\n",
    "    shutil.copytree('./results', f\"{backup_dir}/results\", dirs_exist_ok=True)\n",
    "    print(\"‚úÖ Results saved\")\n",
    "\n",
    "# Copy logs\n",
    "if os.path.exists('./logs'):\n",
    "    print(\"üìù Copying logs...\")\n",
    "    shutil.copytree('./logs', f\"{backup_dir}/logs\", dirs_exist_ok=True)\n",
    "    print(\"‚úÖ Logs saved\")\n",
    "\n",
    "# Copy MLflow runs if exists\n",
    "if os.path.exists('./mlruns'):\n",
    "    print(\"üî¨ Copying MLflow runs...\")\n",
    "    shutil.copytree('./mlruns', f\"{backup_dir}/mlruns\", dirs_exist_ok=True)\n",
    "    print(\"‚úÖ MLflow runs saved\")\n",
    "\n",
    "print(f\"\\nüéâ All results backed up to Google Drive!\")\n",
    "print(f\"üìÅ Location: {backup_dir}\")\n",
    "\n",
    "# Show backup size\n",
    "!du -sh \"{backup_dir}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b36800",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ Resume Training from Checkpoint (Optional)\n",
    "\n",
    "If your session disconnected, you can resume training from the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bafdec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, restore checkpoints from Google Drive\n",
    "backup_dir = \"/content/drive/MyDrive/dissertation_results_backup_XXXXXXXX_XXXXXX\"  # UPDATE THIS\n",
    "\n",
    "if os.path.exists(f\"{backup_dir}/checkpoints\"):\n",
    "    print(\"üîÑ Restoring checkpoints from Google Drive...\")\n",
    "    shutil.copytree(f\"{backup_dir}/checkpoints\", './checkpoints', dirs_exist_ok=True)\n",
    "    print(\"‚úÖ Checkpoints restored\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No checkpoints found. Update backup_dir path.\")\n",
    "\n",
    "# Resume training with the restored checkpoint\n",
    "!python -m src.training.train_baseline \\\n",
    "    --config configs/experiments/adversarial_training_trades_isic.yaml \\\n",
    "    --device cuda \\\n",
    "    --resume_from ./checkpoints/trades_isic/last.pt \\\n",
    "    --max_epochs 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70738939",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí° Useful Tips & Troubleshooting\n",
    "\n",
    "### Keep Session Alive\n",
    "Colab sessions disconnect after ~90 minutes of inactivity. Run this to keep it alive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba8604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def keep_colab_alive():\n",
    "    \"\"\"Prevents Colab from disconnecting due to inactivity\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            display(Javascript('window.keepAlive = true'))\n",
    "            time.sleep(60)  # Ping every 60 seconds\n",
    "        except:\n",
    "            break\n",
    "\n",
    "# Start keep-alive thread\n",
    "thread = threading.Thread(target=keep_colab_alive, daemon=True)\n",
    "thread.start()\n",
    "print(\"‚úÖ Keep-alive thread started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f96c27",
   "metadata": {},
   "source": [
    "### Monitor GPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4759abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU memory usage\n",
    "!nvidia-smi\n",
    "\n",
    "# Or use Python\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nüéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"üíæ Memory Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"üíæ Max Memory Allocated: {torch.cuda.max_memory_allocated(0) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51268cd9",
   "metadata": {},
   "source": [
    "### Check Available Disk Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "!df -h /content\n",
    "!echo \"\"\n",
    "!echo \"Project size:\"\n",
    "!du -sh /content/tri-objective-robust-xai-medimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eeeb76",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Next Steps\n",
    "\n",
    "1. **Run Training**: Choose one of the training examples above and start training\n",
    "2. **Monitor Progress**: Check logs directory or use TensorBoard/MLflow\n",
    "3. **Save Checkpoints**: Run the backup cell regularly (every few epochs)\n",
    "4. **Evaluate Results**: After training, use evaluation scripts in `scripts/evaluation/`\n",
    "5. **Experiment**: Try different hyperparameters by modifying config files\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- **Documentation**: See `/docs` folder in the repository\n",
    "- **Phase 5.1 Details**: Check `PHASE_5.1_COMPLETE.md` for implementation details\n",
    "- **Test Suite**: Run `pytest tests/` to verify all functionality\n",
    "- **Scripts**: Explore `scripts/` for evaluation and analysis tools\n",
    "\n",
    "## ‚ö†Ô∏è Important Reminders\n",
    "\n",
    "1. **Always backup to Google Drive** before session ends\n",
    "2. **Use GPU runtime** (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
    "3. **Keep session alive** using the keep-alive cell above\n",
    "4. **Monitor disk space** - Colab has ~100GB limit\n",
    "5. **Save intermediate checkpoints** every few epochs\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ You're All Set!\n",
    "\n",
    "Your environment is ready for adversarial training on Google Colab Pro. Happy training! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
