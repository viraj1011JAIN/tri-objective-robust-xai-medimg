{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a23a00c",
   "metadata": {},
   "source": [
    "# PHASE 7: TRI-OBJECTIVE LOSS & TRAINING\n",
    "\n",
    "**Author**: Viraj Pankaj Jain  \n",
    "**Institution**: University of Glasgow  \n",
    "**Project**: Tri-Objective Robust XAI for Medical Imaging  \n",
    "**Date**: November 27, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Phase 7 Overview\n",
    "\n",
    "This notebook documents the execution of Phase 7: Tri-Objective Loss & Training.\n",
    "\n",
    "### Objectives\n",
    "1. ‚úÖ **L_task**: Classification loss with temperature scaling\n",
    "2. ‚úÖ **L_rob**: TRADES adversarial robustness (PGD-7, Œµ=8/255)\n",
    "3. ‚úÖ **L_expl**: Explanation stability (SSIM) + Concept alignment (TCAV)\n",
    "\n",
    "### Combined Loss\n",
    "```\n",
    "L_total = L_task + Œª_rob √ó L_rob + Œª_expl √ó L_expl\n",
    "```\n",
    "\n",
    "### Hyperparameters\n",
    "- **Œª_rob** = 0.3 (robustness weight)\n",
    "- **Œª_expl** = 0.1 (explanation weight)\n",
    "- **Œ≤** = 6.0 (TRADES parameter)\n",
    "- **Œµ_rob** = 8/255 (PGD attack strength)\n",
    "- **Œµ_expl** = 2/255 (explanation stability perturbation)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Status: Phase 7.7 - Initial Tri-Objective Validation\n",
    "\n",
    "**Baseline Training Complete**:\n",
    "- ‚úÖ 3 seeds trained (42, 123, 456)\n",
    "- ‚úÖ Mean Accuracy: **64.33% ¬± 3.43%**\n",
    "- ‚úÖ Mean AUROC: **91.27% ¬± 0.74%**\n",
    "- ‚úÖ Dataset: ISIC 2018 (10,015 train, 193 val, 1,512 test)\n",
    "\n",
    "**Tri-Objective Training**: Ready to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6279035",
   "metadata": {},
   "source": [
    "## üöÄ Phase 7.7: Tri-Objective Training Execution\n",
    "\n",
    "### ‚ö†Ô∏è Important: Run from Terminal, Not Notebook\n",
    "\n",
    "**Due to Jupyter path issues, please run the training from a PowerShell terminal instead:**\n",
    "\n",
    "1. Open a new PowerShell terminal\n",
    "2. Navigate to project root: `cd C:\\Users\\Dissertation\\tri-objective-robust-xai-medimg`\n",
    "3. Activate venv: `.\\.venv\\Scripts\\Activate.ps1`\n",
    "4. Run training (choose one):\n",
    "\n",
    "**Option 1 - Single seed (42) - RECOMMENDED SETTINGS:**\n",
    "```powershell\n",
    "python scripts/train_tri_objective_standalone.py --data-root \"data/processed/isic2018\" --seed 42 --device cuda --batch-size 16 --max-epochs 60 --learning-rate 1e-4 --lambda-rob 0.3 --lambda-expl 0.1 --pgd-num-steps 7 --results-dir \"results/tri_objective\" --log-dir \"logs/tri_objective\" --use-mlflow --num-workers 0\n",
    "```\n",
    "\n",
    "**Option 2 - All seeds (42, 123, 456) - Run each separately:**\n",
    "```powershell\n",
    "# Seed 42\n",
    "python scripts/train_tri_objective_standalone.py --data-root \"data/processed/isic2018\" --seed 42 --device cuda --batch-size 16 --max-epochs 60 --learning-rate 1e-4 --lambda-rob 0.3 --lambda-expl 0.1 --pgd-num-steps 7 --results-dir \"results/tri_objective\" --log-dir \"logs/tri_objective\" --use-mlflow --num-workers 0\n",
    "\n",
    "# Seed 123\n",
    "python scripts/train_tri_objective_standalone.py --data-root \"data/processed/isic2018\" --seed 123 --device cuda --batch-size 16 --max-epochs 60 --learning-rate 1e-4 --lambda-rob 0.3 --lambda-expl 0.1 --pgd-num-steps 7 --results-dir \"results/tri_objective\" --log-dir \"logs/tri_objective\" --use-mlflow --num-workers 0\n",
    "\n",
    "# Seed 456\n",
    "python scripts/train_tri_objective_standalone.py --data-root \"data/processed/isic2018\" --seed 456 --device cuda --batch-size 16 --max-epochs 60 --learning-rate 1e-4 --lambda-rob 0.3 --lambda-expl 0.1 --pgd-num-steps 7 --results-dir \"results/tri_objective\" --log-dir \"logs/tri_objective\" --use-mlflow --num-workers 0\n",
    "```\n",
    "\n",
    "**Configuration Notes:**\n",
    "- **Batch size: 16** (reduced from 32 due to GPU memory constraints with adversarial training)\n",
    "- **PGD steps: 7** (adversarial robustness training)\n",
    "- **Œª_rob: 0.3, Œª_expl: 0.1** (tri-objective weights)\n",
    "- **Expected time:** ~2-3 hours per seed (~6-9 hours total for all 3 seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38115a8b",
   "metadata": {},
   "source": [
    "## ‚úÖ Training Status Update\n",
    "\n",
    "**TRAINING IS NOW RUNNING SUCCESSFULLY!** üéâ\n",
    "\n",
    "### What Was Fixed\n",
    "\n",
    "**Issue**: Image tensor dimension mismatch - dataset returned HWC format (Height √ó Width √ó Channels) but PyTorch models expect CHW format (Channels √ó Height √ó Width).\n",
    "\n",
    "**Solution**: Added proper Albumentations transforms with `ToTensorV2()`:\n",
    "- ‚úÖ Train transforms: Augmentation + Normalization + ToTensorV2\n",
    "- ‚úÖ Val/Test transforms: Resize + Normalization + ToTensorV2\n",
    "- ‚úÖ Batch size: 16 (reduced from 32 for GPU memory)\n",
    "\n",
    "### Current Training Details\n",
    "\n",
    "**Configuration**:\n",
    "- Dataset: ISIC 2018 (10,015 train, 193 val, 1,512 test)\n",
    "- Model: ResNet-50 (pretrained, 7 classes)\n",
    "- Batch size: 16\n",
    "- Tri-objective weights: Œª_rob=0.3, Œª_expl=0.1\n",
    "- PGD steps: 7 (adversarial training)\n",
    "- Device: CUDA (RTX 3050 Laptop GPU)\n",
    "\n",
    "**Training Progress**:\n",
    "- ‚úÖ Environment initialized\n",
    "- ‚úÖ Datasets loaded correctly\n",
    "- ‚úÖ Model built successfully\n",
    "- ‚úÖ TriObjectiveTrainer initialized\n",
    "- ‚úÖ MLflow logging active\n",
    "- ‚úÖ **Training in progress** (batches processing every ~30 seconds)\n",
    "\n",
    "**Expected Warnings** (non-critical):\n",
    "- Unicode encoding errors (Œª symbols on Windows console) - harmless\n",
    "- Image normalization warnings (values outside [0,1]) - expected for ImageNet normalization\n",
    "- get_embeddings() warnings - model correctly uses forward pass\n",
    "\n",
    "### Performance Estimate\n",
    "- **Time per batch**: ~30 seconds (adversarial training is compute-intensive)\n",
    "- **Batches per epoch**: ~626 (10,015 samples / 16 batch size)\n",
    "- **Time per epoch**: ~5-6 hours\n",
    "- **Full training (60 epochs)**: ~5-6 days per seed\n",
    "\n",
    "**Recommendation**: For Phase 7.7 validation, consider:\n",
    "- Running fewer epochs (e.g., 20-30) to get initial results faster\n",
    "- Using the current 2-epoch test to verify everything works\n",
    "- Then running full 60-epoch training overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb847883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENVIRONMENT CHECK\n",
      "================================================================================\n",
      "Python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "PyTorch: 2.9.1+cu128\n",
      "CUDA Available: True\n",
      "CUDA Device: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "CUDA Memory: 4.29 GB\n",
      "Current Working Dir: c:\\\n",
      "Project Root: c:\\\n",
      "Data path: c:\\data\\processed\\isic2018\n",
      "Data exists: False\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Check environment\n",
    "print(\"=\" * 80)\n",
    "print(\"ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"Current Working Dir: {Path.cwd()}\")\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Verify data path exists\n",
    "data_path = PROJECT_ROOT / \"data\" / \"processed\" / \"isic2018\"\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"Data exists: {data_path.exists()}\")\n",
    "if data_path.exists():\n",
    "    csv_path = data_path / \"metadata_processed.csv\"\n",
    "    print(f\"CSV exists: {csv_path.exists()}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb8c8b",
   "metadata": {},
   "source": [
    "### Monitor Training with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7673ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow UI starting...\n",
      "‚úÖ MLflow UI running at: http://localhost:5000\n",
      "View experiment: 'Tri-Objective-XAI-Dermoscopy'\n",
      "\n",
      "To stop: mlflow_process.terminate()\n",
      "‚úÖ MLflow UI running at: http://localhost:5000\n",
      "View experiment: 'Tri-Objective-XAI-Dermoscopy'\n",
      "\n",
      "To stop: mlflow_process.terminate()\n"
     ]
    }
   ],
   "source": [
    "# Start MLflow UI in background (run in separate terminal)\n",
    "# Command: mlflow ui --port 5000\n",
    "# Then open: http://localhost:5000\n",
    "\n",
    "# Or start from notebook:\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Start MLflow UI\n",
    "mlflow_process = subprocess.Popen(\n",
    "    [\"mlflow\", \"ui\", \"--port\", \"5000\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE\n",
    ")\n",
    "\n",
    "print(\"MLflow UI starting...\")\n",
    "time.sleep(3)\n",
    "print(\"‚úÖ MLflow UI running at: http://localhost:5000\")\n",
    "print(\"View experiment: 'Tri-Objective-XAI-Dermoscopy'\")\n",
    "print(\"\\nTo stop: mlflow_process.terminate()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58d404",
   "metadata": {},
   "source": [
    "## üìä Results Analysis\n",
    "\n",
    "### Load Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64b6bb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Results not found for seed 42\n",
      "‚ö†Ô∏è  Results not found for seed 123\n",
      "‚ö†Ô∏è  Results not found for seed 456\n",
      "\n",
      "Loaded 0 seed results\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load results for all seeds\n",
    "results = {}\n",
    "for seed in [42, 123, 456]:\n",
    "    result_file = f\"../results/tri_objective/tri_objective_seed{seed}_results.json\"\n",
    "    try:\n",
    "        with open(result_file, 'r') as f:\n",
    "            results[seed] = json.load(f)\n",
    "        print(f\"‚úÖ Loaded results for seed {seed}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è  Results not found for seed {seed}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(results)} seed results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a28723",
   "metadata": {},
   "source": [
    "### Compare with Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline results (from previous training)\n",
    "baseline_results = {\n",
    "    'accuracy': 0.6433,\n",
    "    'auroc': 0.9127,\n",
    "    'robust_acc': 0.10,  # Estimated (untrained)\n",
    "    'ssim': 0.60,        # Estimated\n",
    "}\n",
    "\n",
    "# Extract tri-objective results (placeholder - update after training)\n",
    "tri_obj_results = {\n",
    "    'accuracy': None,  # Will be populated after training\n",
    "    'auroc': None,\n",
    "    'robust_acc': None,\n",
    "    'ssim': None,\n",
    "    'artifact_tcav': None,\n",
    "    'medical_tcav': None,\n",
    "}\n",
    "\n",
    "# Expected targets\n",
    "targets = {\n",
    "    'accuracy': 0.83,        # ‚â•83% (allow -2% from baseline)\n",
    "    'robust_acc': 0.45,      # ‚â•45% (+35pp from baseline)\n",
    "    'ssim': 0.75,            # ‚â•75% (+15pp from baseline)\n",
    "    'artifact_tcav': 0.20,   # ‚â§20% (-25pp from baseline)\n",
    "    'medical_tcav': 0.68,    # ‚â•68% (+10pp from baseline)\n",
    "}\n",
    "\n",
    "print(\"BASELINE vs TRI-OBJECTIVE vs TARGETS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Metric':<20} {'Baseline':<15} {'Tri-Obj':<15} {'Target':<15} {'Status'}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for metric in ['accuracy', 'auroc', 'robust_acc', 'ssim']:\n",
    "    baseline = baseline_results.get(metric, 'N/A')\n",
    "    triobj = tri_obj_results.get(metric, 'N/A')\n",
    "    target = targets.get(metric, 'N/A')\n",
    "    \n",
    "    print(f\"{metric:<20} {baseline:<15} {triobj:<15} {target:<15} {'‚è≥ Pending'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38345f52",
   "metadata": {},
   "source": [
    "## ‚úÖ Phase 7.7 Completion Checklist\n",
    "\n",
    "### Phase 7 Criteria\n",
    "- ‚úÖ **Explanation loss implemented and tested**\n",
    "  - L_stab: SSIM stability loss\n",
    "  - L_concept: TCAV regularization\n",
    "- ‚úÖ **Tri-objective loss integrated**\n",
    "  - Combined L_total = L_task + Œª_rob √ó L_rob + Œª_expl √ó L_expl\n",
    "- ‚úÖ **Tri-objective trainer working end-to-end**\n",
    "  - PGD adversarial training\n",
    "  - Explanation loss computation\n",
    "  - MLflow logging\n",
    "- ‚è≥ **Tri-objective models trained (3 seeds √ó 1 dataset)**\n",
    "  - ISIC 2018: Pending execution\n",
    "  - NIH ChestX-ray14: Phase 7.6 (future)\n",
    "- ‚è≥ **Initial validation shows improvements**\n",
    "  - Robust accuracy: Target +35pp\n",
    "  - SSIM stability: Target +15pp\n",
    "  - TCAV alignment: Target improvements\n",
    "- ‚úÖ **All training logged to MLflow**\n",
    "  - Experiment setup complete\n",
    "  - Real-time monitoring ready\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Next Steps\n",
    "\n",
    "1. **Execute training** using one of the options above\n",
    "2. **Monitor in MLflow** at http://localhost:5000\n",
    "3. **Validate results** against targets (accuracy ‚â•83%, robust ‚â•45%, SSIM ‚â•75%)\n",
    "4. **Document findings** in dissertation\n",
    "5. **Proceed to Phase 8** (comprehensive evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679ab80",
   "metadata": {},
   "source": [
    "## üìã Phase 7.7: Initial Tri-Objective Validation Checklist\n",
    "\n",
    "This section provides comprehensive evaluation tools for Phase 7.7 validation.\n",
    "\n",
    "### Validation Objectives\n",
    "1. ‚úÖ **Clean Accuracy**: Similar to baseline or slightly lower (allow -2%)\n",
    "2. ‚úÖ **Robust Accuracy**: Significant improvement over baseline (~+35pp)\n",
    "3. ‚úÖ **SSIM Stability**: Improved explanation consistency (~+15pp)\n",
    "4. ‚úÖ **Artifact TCAV**: Decreased artifact reliance (~-25pp)\n",
    "5. ‚úÖ **Medical TCAV**: Increased medical concept alignment (~+10pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Phase 7.7 Quick Evaluation Setup\n",
    "Run this cell to set up evaluation utilities\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Add project root\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.models.build import build_model\n",
    "from src.datasets.isic import ISICDataset\n",
    "from src.datasets.transforms import get_isic_transforms\n",
    "from src.attacks.pgd import PGD\n",
    "from src.xai.gradcam import GradCAM\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Evaluation device: {device}\")\n",
    "\n",
    "# Baseline results (Phase 7.6)\n",
    "BASELINE_RESULTS = {\n",
    "    'seed_42': {\n",
    "        'clean_acc': 0.6435,\n",
    "        'auroc': 0.9224,\n",
    "        'robust_acc': 0.10,  # Estimated\n",
    "        'ssim': 0.60,  # Estimated\n",
    "        'artifact_tcav': 0.45,  # Estimated\n",
    "        'medical_tcav': 0.58  # Estimated\n",
    "    },\n",
    "    'seed_123': {\n",
    "        'clean_acc': 0.6012,\n",
    "        'auroc': 0.9113,\n",
    "        'robust_acc': 0.10,\n",
    "        'ssim': 0.60,\n",
    "        'artifact_tcav': 0.45,\n",
    "        'medical_tcav': 0.58\n",
    "    },\n",
    "    'seed_456': {\n",
    "        'clean_acc': 0.6852,\n",
    "        'auroc': 0.9044,\n",
    "        'robust_acc': 0.10,\n",
    "        'ssim': 0.60,\n",
    "        'artifact_tcav': 0.45,\n",
    "        'medical_tcav': 0.58\n",
    "    },\n",
    "    'mean': {\n",
    "        'clean_acc': 0.6433,\n",
    "        'auroc': 0.9127,\n",
    "        'robust_acc': 0.10,\n",
    "        'ssim': 0.60,\n",
    "        'artifact_tcav': 0.45,\n",
    "        'medical_tcav': 0.58\n",
    "    }\n",
    "}\n",
    "\n",
    "# Phase 7.7 Targets\n",
    "PHASE_77_TARGETS = {\n",
    "    'clean_acc': 0.83,  # ‚â•83% (allow -2% from baseline 85%)\n",
    "    'robust_acc': 0.45,  # ‚â•45% (+35pp from baseline ~10%)\n",
    "    'ssim': 0.75,  # ‚â•75% (+15pp from baseline ~60%)\n",
    "    'artifact_tcav': 0.20,  # ‚â§20% (-25pp from baseline ~45%)\n",
    "    'medical_tcav': 0.68  # ‚â•68% (+10pp from baseline ~58%)\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Baseline results loaded\")\n",
    "print(\"‚úÖ Phase 7.7 targets defined\")\n",
    "print(\"\\nReady for evaluation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3724b4",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Load Trained Model and Evaluate Clean Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate Clean Accuracy\n",
    "Expected: Similar to baseline (‚â•83%, allow -2% drop)\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_clean_accuracy(checkpoint_path: Path, seed: int = 42) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate clean (non-adversarial) accuracy on test set.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'accuracy': float, 'loss': float}\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CLEAN ACCURACY EVALUATION - Seed {seed}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model = build_model(\n",
    "        name='resnet50',\n",
    "        num_classes=7,\n",
    "        pretrained=False  # Load from checkpoint\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    print(\"‚úÖ Model loaded\")\n",
    "    \n",
    "    # Load test dataset\n",
    "    test_transforms = get_isic_transforms(split='test', image_size=224)\n",
    "    test_dataset = ISICDataset(\n",
    "        root=PROJECT_ROOT / \"data\" / \"processed\" / \"isic2018\",\n",
    "        split=\"test\",\n",
    "        transforms=test_transforms\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    print(f\"‚úÖ Test dataset loaded: {len(test_dataset)} samples\")\n",
    "    \n",
    "    # Evaluate\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            if len(batch) == 3:\n",
    "                images, labels, _ = batch\n",
    "            else:\n",
    "                images, labels = batch\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Batch {batch_idx + 1}/{len(test_loader)}: \"\n",
    "                      f\"Acc={100*correct/total:.2f}%\")\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTS:\")\n",
    "    print(f\"  Clean Accuracy: {accuracy*100:.2f}% ({correct}/{total})\")\n",
    "    print(f\"  Average Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Baseline: {BASELINE_RESULTS['mean']['clean_acc']*100:.2f}%\")\n",
    "    print(f\"  Target: {PHASE_77_TARGETS['clean_acc']*100:.2f}%\")\n",
    "    \n",
    "    if accuracy >= PHASE_77_TARGETS['clean_acc']:\n",
    "        print(f\"  ‚úÖ PASS: Meets target (‚â•{PHASE_77_TARGETS['clean_acc']*100:.0f}%)\")\n",
    "    elif accuracy >= BASELINE_RESULTS['mean']['clean_acc'] - 0.02:\n",
    "        print(f\"  ‚ö†Ô∏è  ACCEPTABLE: Within -2% of baseline\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå FAIL: Below acceptable threshold\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'loss': avg_loss\n",
    "    }\n",
    "\n",
    "# Example usage (run after training completes):\n",
    "# checkpoint_path = PROJECT_ROOT / \"checkpoints\" / \"tri_objective\" / \"best.pt\"\n",
    "# if checkpoint_path.exists():\n",
    "#     clean_results = evaluate_clean_accuracy(checkpoint_path, seed=42)\n",
    "# else:\n",
    "#     print(f\"‚ö†Ô∏è  Checkpoint not found: {checkpoint_path}\")\n",
    "#     print(\"Run this cell after training completes\")\n",
    "\n",
    "print(\"‚úÖ Clean accuracy evaluation function ready\")\n",
    "print(\"Uncomment the example usage code after training completes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf7d29",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Evaluate Robust Accuracy (PGD Attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55648bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate Robust Accuracy\n",
    "Expected: Significant improvement (‚â•45%, +35pp from baseline ~10%)\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_robust_accuracy(\n",
    "    checkpoint_path: Path,\n",
    "    seed: int = 42,\n",
    "    epsilon: float = 8/255,\n",
    "    num_steps: int = 20,\n",
    "    step_size: float = 2/255\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate robustness against PGD adversarial attacks.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to model checkpoint\n",
    "        seed: Random seed\n",
    "        epsilon: PGD attack strength (default: 8/255)\n",
    "        num_steps: PGD steps (default: 20 for evaluation)\n",
    "        step_size: PGD step size (default: 2/255)\n",
    "        \n",
    "    Returns:\n",
    "        dict: {'robust_acc': float, 'clean_acc': float, 'attack_success_rate': float}\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ROBUST ACCURACY EVALUATION - Seed {seed}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"PGD Attack Config: Œµ={epsilon:.4f}, steps={num_steps}, Œ±={step_size:.4f}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"\\nLoading checkpoint: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model = build_model(\n",
    "        name='resnet50',\n",
    "        num_classes=7,\n",
    "        pretrained=False\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    print(\"‚úÖ Model loaded\")\n",
    "    \n",
    "    # Initialize PGD attack\n",
    "    pgd_attack = PGD(\n",
    "        epsilon=epsilon,\n",
    "        num_steps=num_steps,\n",
    "        step_size=step_size,\n",
    "        random_start=True,\n",
    "        device=device\n",
    "    )\n",
    "    print(\"‚úÖ PGD attack initialized\")\n",
    "    \n",
    "    # Load test dataset\n",
    "    test_transforms = get_isic_transforms(split='test', image_size=224)\n",
    "    test_dataset = ISICDataset(\n",
    "        root=PROJECT_ROOT / \"data\" / \"processed\" / \"isic2018\",\n",
    "        split=\"test\",\n",
    "        transforms=test_transforms\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,  # Smaller batch for adversarial evaluation\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    print(f\"‚úÖ Test dataset loaded: {len(test_dataset)} samples\")\n",
    "    \n",
    "    # Evaluate\n",
    "    clean_correct = 0\n",
    "    robust_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    print(\"\\nGenerating adversarial examples and evaluating...\")\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        if len(batch) == 3:\n",
    "            images, labels, _ = batch\n",
    "        else:\n",
    "            images, labels = batch\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clean predictions\n",
    "        with torch.no_grad():\n",
    "            clean_outputs = model(images)\n",
    "            _, clean_pred = torch.max(clean_outputs, 1)\n",
    "            clean_correct += (clean_pred == labels).sum().item()\n",
    "        \n",
    "        # Generate adversarial examples\n",
    "        images_adv = pgd_attack(model, images, labels)\n",
    "        \n",
    "        # Robust predictions\n",
    "        with torch.no_grad():\n",
    "            adv_outputs = model(images_adv)\n",
    "            _, adv_pred = torch.max(adv_outputs, 1)\n",
    "            robust_correct += (adv_pred == labels).sum().item()\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Batch {batch_idx + 1}/{len(test_loader)}: \"\n",
    "                  f\"Clean={100*clean_correct/total:.2f}%, \"\n",
    "                  f\"Robust={100*robust_correct/total:.2f}%\")\n",
    "    \n",
    "    clean_acc = clean_correct / total\n",
    "    robust_acc = robust_correct / total\n",
    "    attack_success = (clean_correct - robust_correct) / clean_correct if clean_correct > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTS:\")\n",
    "    print(f\"  Clean Accuracy: {clean_acc*100:.2f}% ({clean_correct}/{total})\")\n",
    "    print(f\"  Robust Accuracy: {robust_acc*100:.2f}% ({robust_correct}/{total})\")\n",
    "    print(f\"  Attack Success Rate: {attack_success*100:.2f}%\")\n",
    "    print(f\"  Baseline Robust: {BASELINE_RESULTS['mean']['robust_acc']*100:.2f}%\")\n",
    "    print(f\"  Target Robust: {PHASE_77_TARGETS['robust_acc']*100:.2f}%\")\n",
    "    print(f\"  Improvement: +{(robust_acc - BASELINE_RESULTS['mean']['robust_acc'])*100:.1f}pp\")\n",
    "    \n",
    "    if robust_acc >= PHASE_77_TARGETS['robust_acc']:\n",
    "        print(f\"  ‚úÖ PASS: Meets target (‚â•{PHASE_77_TARGETS['robust_acc']*100:.0f}%)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå FAIL: Below target ({robust_acc*100:.1f}% < {PHASE_77_TARGETS['robust_acc']*100:.0f}%)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'robust_acc': robust_acc,\n",
    "        'clean_acc': clean_acc,\n",
    "        'attack_success_rate': attack_success\n",
    "    }\n",
    "\n",
    "# Example usage (run after training completes):\n",
    "# checkpoint_path = PROJECT_ROOT / \"checkpoints\" / \"tri_objective\" / \"best.pt\"\n",
    "# if checkpoint_path.exists():\n",
    "#     robust_results = evaluate_robust_accuracy(checkpoint_path, seed=42)\n",
    "# else:\n",
    "#     print(f\"‚ö†Ô∏è  Checkpoint not found: {checkpoint_path}\")\n",
    "#     print(\"Run this cell after training completes\")\n",
    "\n",
    "print(\"‚úÖ Robust accuracy evaluation function ready\")\n",
    "print(\"Uncomment the example usage code after training completes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad74d41a",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Evaluate SSIM Explanation Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b70aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate SSIM Explanation Stability\n",
    "Expected: Improved stability (‚â•75%, +15pp from baseline ~60%)\n",
    "\"\"\"\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def evaluate_ssim_stability(\n",
    "    checkpoint_path: Path,\n",
    "    seed: int = 42,\n",
    "    epsilon: float = 2/255,\n",
    "    num_samples: int = 200\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate SSIM between clean and perturbed explanations.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to model checkpoint\n",
    "        seed: Random seed\n",
    "        epsilon: Perturbation strength (default: 2/255)\n",
    "        num_samples: Number of samples to evaluate\n",
    "        \n",
    "    Returns:\n",
    "        dict: {'mean_ssim': float, 'std_ssim': float}\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SSIM EXPLANATION STABILITY EVALUATION - Seed {seed}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Perturbation: Œµ={epsilon:.4f}, Samples={num_samples}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"\\nLoading checkpoint: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model = build_model(\n",
    "        name='resnet50',\n",
    "        num_classes=7,\n",
    "        pretrained=False\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    print(\"‚úÖ Model loaded\")\n",
    "    \n",
    "    # Initialize Grad-CAM\n",
    "    gradcam = GradCAM(model, target_layer='layer4')\n",
    "    print(\"‚úÖ Grad-CAM initialized\")\n",
    "    \n",
    "    # Load test dataset\n",
    "    test_transforms = get_isic_transforms(split='test', image_size=224)\n",
    "    test_dataset = ISICDataset(\n",
    "        root=PROJECT_ROOT / \"data\" / \"processed\" / \"isic2018\",\n",
    "        split=\"test\",\n",
    "        transforms=test_transforms\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,  # Process one at a time for explanations\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    print(f\"‚úÖ Test dataset loaded\")\n",
    "    \n",
    "    # Evaluate SSIM\n",
    "    ssim_scores = []\n",
    "    \n",
    "    print(\"\\nComputing SSIM scores...\")\n",
    "    for idx, batch in enumerate(test_loader):\n",
    "        if idx >= num_samples:\n",
    "            break\n",
    "            \n",
    "        if len(batch) == 3:\n",
    "            images, labels, _ = batch\n",
    "        else:\n",
    "            images, labels = batch\n",
    "        \n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Generate clean explanation\n",
    "        with torch.enable_grad():\n",
    "            heatmap_clean = gradcam.generate_heatmap(\n",
    "                images,\n",
    "                target_class=None  # Use predicted class\n",
    "            )\n",
    "        \n",
    "        # Generate perturbed image\n",
    "        noise = torch.randn_like(images) * epsilon\n",
    "        images_pert = torch.clamp(images + noise, -3, 3)  # Clamp to reasonable range\n",
    "        \n",
    "        # Generate perturbed explanation\n",
    "        with torch.enable_grad():\n",
    "            heatmap_pert = gradcam.generate_heatmap(\n",
    "                images_pert,\n",
    "                target_class=None\n",
    "            )\n",
    "        \n",
    "        # Compute SSIM\n",
    "        hm_clean = heatmap_clean.cpu().numpy()\n",
    "        hm_pert = heatmap_pert.cpu().numpy()\n",
    "        \n",
    "        ssim_score = ssim(\n",
    "            hm_clean,\n",
    "            hm_pert,\n",
    "            data_range=hm_clean.max() - hm_clean.min()\n",
    "        )\n",
    "        ssim_scores.append(ssim_score)\n",
    "        \n",
    "        if (idx + 1) % 50 == 0:\n",
    "            print(f\"Processed {idx + 1}/{num_samples}: Mean SSIM={np.mean(ssim_scores):.4f}\")\n",
    "    \n",
    "    mean_ssim = np.mean(ssim_scores)\n",
    "    std_ssim = np.std(ssim_scores)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTS:\")\n",
    "    print(f\"  Mean SSIM: {mean_ssim:.4f} ¬± {std_ssim:.4f}\")\n",
    "    print(f\"  Baseline SSIM: {BASELINE_RESULTS['mean']['ssim']:.4f}\")\n",
    "    print(f\"  Target SSIM: {PHASE_77_TARGETS['ssim']:.4f}\")\n",
    "    print(f\"  Improvement: +{(mean_ssim - BASELINE_RESULTS['mean']['ssim']):.4f}\")\n",
    "    \n",
    "    if mean_ssim >= PHASE_77_TARGETS['ssim']:\n",
    "        print(f\"  ‚úÖ PASS: Meets target (‚â•{PHASE_77_TARGETS['ssim']:.2f})\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå FAIL: Below target ({mean_ssim:.4f} < {PHASE_77_TARGETS['ssim']:.2f})\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'mean_ssim': mean_ssim,\n",
    "        'std_ssim': std_ssim,\n",
    "        'all_scores': ssim_scores\n",
    "    }\n",
    "\n",
    "# Example usage (run after training completes):\n",
    "# checkpoint_path = PROJECT_ROOT / \"checkpoints\" / \"tri_objective\" / \"best.pt\"\n",
    "# if checkpoint_path.exists():\n",
    "#     ssim_results = evaluate_ssim_stability(checkpoint_path, seed=42)\n",
    "# else:\n",
    "#     print(f\"‚ö†Ô∏è  Checkpoint not found: {checkpoint_path}\")\n",
    "#     print(\"Run this cell after training completes\")\n",
    "\n",
    "print(\"‚úÖ SSIM stability evaluation function ready\")\n",
    "print(\"‚ö†Ô∏è  Note: This evaluation requires Grad-CAM and may take 10-15 minutes\")\n",
    "print(\"Uncomment the example usage code after training completes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186b04c",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Comprehensive Validation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e029bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate Comprehensive Phase 7.7 Validation Report\n",
    "Run all evaluations and generate summary report\n",
    "\"\"\"\n",
    "\n",
    "def generate_phase77_validation_report(\n",
    "    checkpoint_path: Path,\n",
    "    seed: int = 42,\n",
    "    save_report: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run comprehensive Phase 7.7 validation and generate report.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to trained model checkpoint\n",
    "        seed: Random seed\n",
    "        save_report: Save report to JSON file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Complete validation results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PHASE 7.7 COMPREHENSIVE VALIDATION REPORT\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    results = {\n",
    "        'seed': seed,\n",
    "        'checkpoint': str(checkpoint_path),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # 1. Clean Accuracy\n",
    "        print(\"1Ô∏è‚É£  Evaluating Clean Accuracy...\")\n",
    "        clean_results = evaluate_clean_accuracy(checkpoint_path, seed)\n",
    "        results['clean_accuracy'] = clean_results\n",
    "        \n",
    "        # 2. Robust Accuracy\n",
    "        print(\"\\n2Ô∏è‚É£  Evaluating Robust Accuracy...\")\n",
    "        robust_results = evaluate_robust_accuracy(checkpoint_path, seed)\n",
    "        results['robust_accuracy'] = robust_results\n",
    "        \n",
    "        # 3. SSIM Stability\n",
    "        print(\"\\n3Ô∏è‚É£  Evaluating SSIM Stability...\")\n",
    "        ssim_results = evaluate_ssim_stability(checkpoint_path, seed, num_samples=200)\n",
    "        results['ssim_stability'] = ssim_results\n",
    "        \n",
    "        # 4. Summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PHASE 7.7 VALIDATION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create summary table\n",
    "        metrics = {\n",
    "            'Clean Accuracy': {\n",
    "                'value': clean_results['accuracy'],\n",
    "                'baseline': BASELINE_RESULTS['mean']['clean_acc'],\n",
    "                'target': PHASE_77_TARGETS['clean_acc'],\n",
    "                'format': '.2%'\n",
    "            },\n",
    "            'Robust Accuracy': {\n",
    "                'value': robust_results['robust_acc'],\n",
    "                'baseline': BASELINE_RESULTS['mean']['robust_acc'],\n",
    "                'target': PHASE_77_TARGETS['robust_acc'],\n",
    "                'format': '.2%'\n",
    "            },\n",
    "            'SSIM Stability': {\n",
    "                'value': ssim_results['mean_ssim'],\n",
    "                'baseline': BASELINE_RESULTS['mean']['ssim'],\n",
    "                'target': PHASE_77_TARGETS['ssim'],\n",
    "                'format': '.4f'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'Metric':<20} {'Value':<12} {'Baseline':<12} {'Target':<12} {'Œî':<10} {'Status'}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        all_pass = True\n",
    "        for metric_name, metric_data in metrics.items():\n",
    "            val = metric_data['value']\n",
    "            baseline = metric_data['baseline']\n",
    "            target = metric_data['target']\n",
    "            fmt = metric_data['format']\n",
    "            \n",
    "            delta = val - baseline\n",
    "            \n",
    "            # Determine status\n",
    "            if metric_name in ['Clean Accuracy', 'Robust Accuracy', 'SSIM Stability']:\n",
    "                passed = val >= target\n",
    "            else:\n",
    "                passed = val <= target  # For metrics where lower is better\n",
    "            \n",
    "            all_pass = all_pass and passed\n",
    "            status = \"‚úÖ PASS\" if passed else \"‚ùå FAIL\"\n",
    "            \n",
    "            print(f\"{metric_name:<20} {val:{fmt}:<12} {baseline:{fmt}:<12} \"\n",
    "                  f\"{target:{fmt}:<12} {delta:+.4f}    {status}\")\n",
    "        \n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        if all_pass:\n",
    "            print(\"\\nüéâ ALL VALIDATION CRITERIA PASSED!\")\n",
    "            print(\"Phase 7.7 Initial Tri-Objective Validation: SUCCESSFUL\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  Some validation criteria not met\")\n",
    "            print(\"Review individual metric results above\")\n",
    "        \n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        results['summary'] = {\n",
    "            'all_pass': all_pass,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "        \n",
    "        # Save report\n",
    "        if save_report:\n",
    "            report_path = PROJECT_ROOT / \"results\" / \"tri_objective\" / f\"phase77_validation_seed{seed}.json\"\n",
    "            report_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            with open(report_path, 'w') as f:\n",
    "                json.dump(results, f, indent=2, default=str)\n",
    "            \n",
    "            print(f\"‚úÖ Report saved to: {report_path}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during validation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return results\n",
    "\n",
    "# Example usage (run after training completes):\n",
    "# checkpoint_path = PROJECT_ROOT / \"checkpoints\" / \"tri_objective\" / \"best.pt\"\n",
    "# if checkpoint_path.exists():\n",
    "#     validation_report = generate_phase77_validation_report(checkpoint_path, seed=42)\n",
    "# else:\n",
    "#     print(f\"‚ö†Ô∏è  Checkpoint not found: {checkpoint_path}\")\n",
    "#     print(\"Run this cell after training completes\")\n",
    "\n",
    "from datetime import datetime\n",
    "print(\"‚úÖ Comprehensive validation report function ready\")\n",
    "print(\"Uncomment the example usage code after training completes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcef060",
   "metadata": {},
   "source": [
    "### üìà Monitor Training Progress (During Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a5dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quick Training Progress Check\n",
    "Run this cell to check training logs and early metrics\n",
    "\"\"\"\n",
    "\n",
    "def check_training_progress(log_dir: Path = None, seed: int = 42):\n",
    "    \"\"\"\n",
    "    Check training progress from log files.\n",
    "    \"\"\"\n",
    "    if log_dir is None:\n",
    "        log_dir = PROJECT_ROOT / \"logs\" / \"tri_objective\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING PROGRESS CHECK - Seed {seed}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Find latest log file\n",
    "    log_files = list(log_dir.glob(f\"tri_objective_seed{seed}_*.log\"))\n",
    "    \n",
    "    if not log_files:\n",
    "        print(f\"‚ö†Ô∏è  No log files found in {log_dir}\")\n",
    "        print(\"Training may not have started yet\")\n",
    "        return\n",
    "    \n",
    "    latest_log = max(log_files, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"Reading log: {latest_log.name}\")\n",
    "    \n",
    "    # Parse log file\n",
    "    with open(latest_log, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Extract key information\n",
    "    epochs_info = []\n",
    "    current_epoch = None\n",
    "    \n",
    "    for line in lines:\n",
    "        # Look for epoch information\n",
    "        if 'Epoch' in line and 'train_loss' in line:\n",
    "            try:\n",
    "                # Extract metrics from epoch summary\n",
    "                if 'train_loss' in line:\n",
    "                    parts = line.split('train_loss')\n",
    "                    if len(parts) > 1:\n",
    "                        epochs_info.append(line.strip())\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Display progress\n",
    "    if epochs_info:\n",
    "        print(f\"\\nüìä Training Progress:\")\n",
    "        print(f\"  Total epoch summaries found: {len(epochs_info)}\")\n",
    "        print(f\"\\n  Latest epoch logs:\")\n",
    "        for log in epochs_info[-3:]:  # Show last 3 epochs\n",
    "            print(f\"    {log}\")\n",
    "    else:\n",
    "        print(\"\\n‚è≥ Training in progress...\")\n",
    "        print(f\"   Log file size: {latest_log.stat().st_size / 1024:.2f} KB\")\n",
    "        print(f\"   Last modified: {datetime.fromtimestamp(latest_log.stat().st_mtime)}\")\n",
    "    \n",
    "    # Check for errors\n",
    "    errors = [line for line in lines if 'ERROR' in line or 'Error' in line]\n",
    "    if errors:\n",
    "        print(f\"\\n‚ö†Ô∏è  Found {len(errors)} error(s) in log:\")\n",
    "        for err in errors[-5:]:  # Show last 5 errors\n",
    "            print(f\"    {err.strip()}\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ No errors detected in log\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "# Run progress check\n",
    "try:\n",
    "    check_training_progress(seed=42)\n",
    "except Exception as e:\n",
    "    print(f\"Error checking progress: {e}\")\n",
    "    print(\"\\nTo manually check:\")\n",
    "    print(f\"  1. Open logs/tri_objective/ directory\")\n",
    "    print(f\"  2. Find tri_objective_seed42_*.log file\")\n",
    "    print(f\"  3. Tail the file to see latest progress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1102fd1",
   "metadata": {},
   "source": [
    "## ‚úÖ Phase 7.7 Complete Validation Checklist\n",
    "\n",
    "### Quick Evaluation During/After Training\n",
    "\n",
    "#### 1Ô∏è‚É£ Clean Accuracy Evaluation\n",
    "- [ ] Load trained model checkpoint\n",
    "- [ ] Evaluate on test set (1,512 samples)\n",
    "- [ ] **Expected**: ‚â•83% (allow -2% from baseline 85%)\n",
    "- [ ] **Status**: ‚è≥ Pending training completion\n",
    "- [ ] **Cell to run**: Cell with `evaluate_clean_accuracy()` function\n",
    "\n",
    "#### 2Ô∏è‚É£ Robust Accuracy Evaluation  \n",
    "- [ ] Load trained model checkpoint\n",
    "- [ ] Run PGD-20 attack (Œµ=8/255)\n",
    "- [ ] Evaluate adversarial accuracy\n",
    "- [ ] **Expected**: ‚â•45% (+35pp from baseline ~10%)\n",
    "- [ ] **Status**: ‚è≥ Pending training completion\n",
    "- [ ] **Cell to run**: Cell with `evaluate_robust_accuracy()` function\n",
    "- [ ] **Time estimate**: ~20-30 minutes\n",
    "\n",
    "#### 3Ô∏è‚É£ SSIM Explanation Stability\n",
    "- [ ] Load trained model checkpoint\n",
    "- [ ] Generate Grad-CAM heatmaps (200 samples)\n",
    "- [ ] Compute SSIM between clean/perturbed\n",
    "- [ ] **Expected**: ‚â•0.75 (+15pp from baseline ~0.60)\n",
    "- [ ] **Status**: ‚è≥ Pending training completion\n",
    "- [ ] **Cell to run**: Cell with `evaluate_ssim_stability()` function\n",
    "- [ ] **Time estimate**: ~10-15 minutes\n",
    "\n",
    "#### 4Ô∏è‚É£ TCAV Concept Alignment (Optional - Future)\n",
    "- [ ] Prepare concept activation vectors (CAVs)\n",
    "  - [ ] Artifact concepts (hair, ruler, gel)\n",
    "  - [ ] Medical concepts (pigment network, vessels)\n",
    "- [ ] Compute TCAV scores\n",
    "- [ ] **Expected**: Artifact ‚â§0.20, Medical ‚â•0.68\n",
    "- [ ] **Status**: ‚è≥ Requires CAV preparation (Phase 7.8)\n",
    "- [ ] **Note**: Can be deferred to comprehensive evaluation\n",
    "\n",
    "### Early Observation of Improvements\n",
    "\n",
    "#### Confirm All Three Objectives Addressed\n",
    "- [ ] **L_task (Classification)**: Model maintains clean accuracy\n",
    "  - Check: Clean accuracy ‚â•83% or within -2% of baseline\n",
    "- [ ] **L_rob (Robustness)**: Model resists adversarial attacks\n",
    "  - Check: Robust accuracy ‚â•45% (major improvement)\n",
    "- [ ] **L_expl (Explanations)**: Explanations are stable\n",
    "  - Check: SSIM ‚â•0.75 (improved consistency)\n",
    "\n",
    "#### Identify Issues Before Full Evaluation\n",
    "- [ ] Check training logs for convergence\n",
    "  - Use: `check_training_progress()` cell\n",
    "- [ ] Verify no overfitting (train vs val loss)\n",
    "  - Monitor: MLflow at http://localhost:5000\n",
    "- [ ] Confirm balanced loss components\n",
    "  - Check: L_task, L_rob, L_expl all contributing\n",
    "- [ ] Validate checkpoints saved correctly\n",
    "  - Location: `checkpoints/tri_objective/best.pt`\n",
    "\n",
    "### Execution Order\n",
    "\n",
    "**Step 1**: Let training complete (2 epochs test: ~10-12 hours, Full 60 epochs: ~5-6 days)\n",
    "\n",
    "**Step 2**: Run comprehensive validation\n",
    "```python\n",
    "# Uncomment and run after training completes:\n",
    "checkpoint_path = PROJECT_ROOT / \"checkpoints\" / \"tri_objective\" / \"best.pt\"\n",
    "validation_report = generate_phase77_validation_report(checkpoint_path, seed=42)\n",
    "```\n",
    "\n",
    "**Step 3**: Review results and decide next steps\n",
    "- ‚úÖ All metrics pass ‚Üí Proceed with full 3-seed training\n",
    "- ‚ö†Ô∏è Some metrics below target ‚Üí Adjust hyperparameters\n",
    "- ‚ùå Training issues ‚Üí Debug and restart\n",
    "\n",
    "### Success Criteria Summary\n",
    "\n",
    "| Metric | Baseline | Target | Status |\n",
    "|--------|----------|--------|--------|\n",
    "| Clean Accuracy | 64.33% | ‚â•83% | ‚è≥ Pending |\n",
    "| Robust Accuracy | ~10% | ‚â•45% | ‚è≥ Pending |\n",
    "| SSIM Stability | ~60% | ‚â•75% | ‚è≥ Pending |\n",
    "| Artifact TCAV | ~45% | ‚â§20% | ‚è≥ Future |\n",
    "| Medical TCAV | ~58% | ‚â•68% | ‚è≥ Future |\n",
    "\n",
    "---\n",
    "\n",
    "**Current Status**: üèÉ Training in progress (2-epoch validation test)  \n",
    "**Next Action**: Wait for training completion, then run validation cells above  \n",
    "**Timeline**: Test completes in ~10-12 hours, full validation takes ~30-45 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
