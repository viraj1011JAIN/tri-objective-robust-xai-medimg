{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: ENVIRONMENT SETUP\n",
    "# ============================================================================\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE 3: BASELINE TRAINING SETUP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Mount Google Drive\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úÖ Google Colab detected, Drive mounted\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚úÖ Local environment detected\")\n",
    "\n",
    "# Clone/update repository\n",
    "if IN_COLAB:\n",
    "    REPO_PATH = Path('/content/tri-objective-robust-xai-medimg')\n",
    "    if not REPO_PATH.exists():\n",
    "        !git clone https://github.com/viraj1011JAIN/tri-objective-robust-xai-medimg.git {REPO_PATH}\n",
    "        print(\"‚úÖ Repository cloned\")\n",
    "    else:\n",
    "        os.chdir(REPO_PATH)\n",
    "        !git pull origin main\n",
    "        print(\"‚úÖ Repository updated\")\n",
    "    \n",
    "    os.chdir(REPO_PATH)\n",
    "    sys.path.insert(0, str(REPO_PATH))\n",
    "    PROJECT_ROOT = REPO_PATH\n",
    "else:\n",
    "    PROJECT_ROOT = Path.cwd().parent\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"üìÅ Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: INSTALL DEPENDENCIES\n",
    "# ============================================================================\n",
    "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q timm albumentations scikit-learn pandas matplotlib seaborn tqdm\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: IMPORTS\n",
    "# ============================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Albumentations for transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Project imports\n",
    "from src.datasets.isic import ISICDataset\n",
    "from src.models.build import build_model\n",
    "from src.utils.reproducibility import set_global_seed\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14823d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: CONFIGURATION\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "CONFIG = {\n",
    "    # Data paths (Google Drive)\n",
    "    'data_root': Path('/content/drive/MyDrive/data/data/isic_2018'),\n",
    "    'checkpoint_dir': Path('/content/drive/MyDrive/checkpoints/baseline'),\n",
    "    'results_dir': Path('/content/drive/MyDrive/results/phase3'),\n",
    "    \n",
    "    # Model\n",
    "    'model_name': 'resnet50',\n",
    "    'num_classes': 7,\n",
    "    'pretrained': True,\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 30,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'num_workers': 2,\n",
    "    \n",
    "    # Image\n",
    "    'image_size': 224,\n",
    "    \n",
    "    # Seeds for reproducibility\n",
    "    'seeds': [42, 123, 456],\n",
    "    \n",
    "    # Class names\n",
    "    'class_names': ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'],\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "CONFIG['checkpoint_dir'].mkdir(parents=True, exist_ok=True)\n",
    "CONFIG['results_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for seed in CONFIG['seeds']:\n",
    "    (CONFIG['checkpoint_dir'] / f'seed_{seed}').mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìä Model: {CONFIG['model_name']}\")\n",
    "print(f\"üìä Classes: {CONFIG['num_classes']}\")\n",
    "print(f\"üìä Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"üìä Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"üìä Seeds: {CONFIG['seeds']}\")\n",
    "print(f\"üìÅ Data: {CONFIG['data_root']}\")\n",
    "print(f\"üìÅ Checkpoints: {CONFIG['checkpoint_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c44444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: DATA PREPARATION\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA PREPARATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Fix metadata paths (Windows backslashes ‚Üí forward slashes)\n",
    "metadata_path = CONFIG['data_root'] / 'metadata.csv'\n",
    "print(f\"üìÑ Loading metadata: {metadata_path}\")\n",
    "\n",
    "df = pd.read_csv(metadata_path)\n",
    "print(f\"   Total samples: {len(df)}\")\n",
    "\n",
    "# Convert backslashes to forward slashes\n",
    "if 'image_path' in df.columns:\n",
    "    df['image_path'] = df['image_path'].str.replace('\\\\', '/', regex=False)\n",
    "    print(\"   ‚úÖ Fixed path separators\")\n",
    "\n",
    "# Save fixed metadata\n",
    "fixed_path = CONFIG['data_root'] / 'metadata_fixed.csv'\n",
    "df.to_csv(fixed_path, index=False)\n",
    "print(f\"   ‚úÖ Saved to: {fixed_path}\")\n",
    "\n",
    "# Show split distribution\n",
    "print(f\"\\nüìä Split Distribution:\")\n",
    "print(df['split'].value_counts())\n",
    "\n",
    "# Show class distribution\n",
    "print(f\"\\nüìä Class Distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: CREATE TRANSFORMS & DATASETS\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"CREATING DATASETS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Training transforms (with augmentation)\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(CONFIG['image_size'], CONFIG['image_size']),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(CONFIG['image_size'], CONFIG['image_size']),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ISICDataset(\n",
    "    root=str(CONFIG['data_root']),\n",
    "    split='train',\n",
    "    transforms=train_transforms,\n",
    "    csv_path=str(fixed_path),\n",
    "    image_column='image_path',\n",
    "    label_column='label'\n",
    ")\n",
    "\n",
    "val_dataset = ISICDataset(\n",
    "    root=str(CONFIG['data_root']),\n",
    "    split='val',\n",
    "    transforms=val_transforms,\n",
    "    csv_path=str(fixed_path),\n",
    "    image_column='image_path',\n",
    "    label_column='label'\n",
    ")\n",
    "\n",
    "test_dataset = ISICDataset(\n",
    "    root=str(CONFIG['data_root']),\n",
    "    split='test',\n",
    "    transforms=val_transforms,\n",
    "    csv_path=str(fixed_path),\n",
    "    image_column='image_path',\n",
    "    label_column='label'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Train samples: {len(train_dataset)}\")\n",
    "print(f\"‚úÖ Val samples: {len(val_dataset)}\")\n",
    "print(f\"‚úÖ Test samples: {len(test_dataset)}\")\n",
    "print(f\"‚úÖ Classes: {train_dataset.class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training', leave=False)\n",
    "    for batch in pbar:\n",
    "        # Handle (images, labels, meta) format\n",
    "        if len(batch) == 3:\n",
    "            images, labels, _ = batch\n",
    "        else:\n",
    "            images, labels = batch\n",
    "            \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds) * 100\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Evaluating', leave=False):\n",
    "            if len(batch) == 3:\n",
    "                images, labels, _ = batch\n",
    "            else:\n",
    "                images, labels = batch\n",
    "                \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': epoch_loss,\n",
    "        'accuracy': accuracy_score(all_labels, all_preds) * 100,\n",
    "        'balanced_accuracy': balanced_accuracy_score(all_labels, all_preds) * 100,\n",
    "        'f1_macro': f1_score(all_labels, all_preds, average='macro') * 100,\n",
    "    }\n",
    "    \n",
    "    # AUROC (one-vs-rest)\n",
    "    try:\n",
    "        metrics['auroc'] = roc_auc_score(all_labels, all_probs, multi_class='ovr') * 100\n",
    "    except:\n",
    "        metrics['auroc'] = 0.0\n",
    "    \n",
    "    return metrics, all_probs, all_labels, all_preds\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: MAIN TRAINING LOOP (ALL 3 SEEDS)\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"BASELINE TRAINING - ALL SEEDS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_seed_results = {}\n",
    "training_history = {}\n",
    "\n",
    "for seed_idx, seed in enumerate(CONFIG['seeds']):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SEED {seed} ({seed_idx+1}/{len(CONFIG['seeds'])})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    set_global_seed(seed)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True, num_workers=CONFIG['num_workers'], pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False, num_workers=CONFIG['num_workers'], pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False, num_workers=CONFIG['num_workers'], pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model(\n",
    "        architecture=CONFIG['model_name'],\n",
    "        num_classes=CONFIG['num_classes'],\n",
    "        pretrained=CONFIG['pretrained']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG['learning_rate'],\n",
    "        weight_decay=CONFIG['weight_decay']\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=CONFIG['epochs'], eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_auroc': []}\n",
    "    best_val_auroc = 0.0\n",
    "    \n",
    "    print(f\"\\nüìä Training for {CONFIG['epochs']} epochs...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        # Train\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_metrics, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_metrics['loss'])\n",
    "        history['val_acc'].append(val_metrics['accuracy'])\n",
    "        history['val_auroc'].append(val_metrics['auroc'])\n",
    "        \n",
    "        # Save best model\n",
    "        if val_metrics['auroc'] > best_val_auroc:\n",
    "            best_val_auroc = val_metrics['auroc']\n",
    "            checkpoint_path = CONFIG['checkpoint_dir'] / f'seed_{seed}' / 'best.pt'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_auroc': best_val_auroc,\n",
    "                'config': CONFIG,\n",
    "            }, checkpoint_path)\n",
    "        \n",
    "        # Print progress every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f\"  Epoch {epoch+1:2d}/{CONFIG['epochs']} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.1f}% | \"\n",
    "                  f\"Val Acc: {val_metrics['accuracy']:.1f}% | Val AUROC: {val_metrics['auroc']:.1f}%\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n‚è±Ô∏è  Training time: {elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    # Final test evaluation\n",
    "    print(f\"\\nüìä Final Test Evaluation...\")\n",
    "    \n",
    "    # Load best model\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    test_metrics, test_probs, test_labels, test_preds = evaluate(\n",
    "        model, test_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ SEED {seed} RESULTS:\")\n",
    "    print(f\"   Test Accuracy: {test_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"   Test Balanced Acc: {test_metrics['balanced_accuracy']:.2f}%\")\n",
    "    print(f\"   Test AUROC: {test_metrics['auroc']:.2f}%\")\n",
    "    print(f\"   Test F1 (macro): {test_metrics['f1_macro']:.2f}%\")\n",
    "    print(f\"   Checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Store results\n",
    "    all_seed_results[seed] = test_metrics\n",
    "    training_history[seed] = history\n",
    "    \n",
    "    # Free memory\n",
    "    del model, optimizer, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ALL SEEDS COMPLETE\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b926c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: AGGREGATE RESULTS\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"AGGREGATED RESULTS (MEAN ¬± STD)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Aggregate across seeds\n",
    "metrics_list = ['accuracy', 'balanced_accuracy', 'auroc', 'f1_macro']\n",
    "\n",
    "print(\"\\nüìä Test Set Performance:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "aggregated = {}\n",
    "for metric in metrics_list:\n",
    "    values = [all_seed_results[seed][metric] for seed in CONFIG['seeds']]\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    aggregated[metric] = {'mean': mean_val, 'std': std_val}\n",
    "    print(f\"   {metric:20s}: {mean_val:.2f}% ¬± {std_val:.2f}%\")\n",
    "\n",
    "print(\"\\nüìä Per-Seed Results:\")\n",
    "print(\"-\" * 50)\n",
    "for seed in CONFIG['seeds']:\n",
    "    r = all_seed_results[seed]\n",
    "    print(f\"   Seed {seed}: Acc={r['accuracy']:.1f}%, AUROC={r['auroc']:.1f}%\")\n",
    "\n",
    "# Save results\n",
    "results_file = CONFIG['results_dir'] / 'baseline_results.json'\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump({\n",
    "        'per_seed': {str(k): v for k, v in all_seed_results.items()},\n",
    "        'aggregated': aggregated,\n",
    "        'config': {k: str(v) if isinstance(v, Path) else v for k, v in CONFIG.items()}\n",
    "    }, f, indent=2)\n",
    "print(f\"\\n‚úÖ Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: VISUALIZATION - TRAINING CURVES\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING VISUALIZATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Training Loss\n",
    "ax = axes[0, 0]\n",
    "for i, seed in enumerate(CONFIG['seeds']):\n",
    "    ax.plot(training_history[seed]['train_loss'], label=f'Seed {seed}', color=colors[i], linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Training Loss', fontsize=12)\n",
    "ax.set_title('Training Loss Curves', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Validation Loss\n",
    "ax = axes[0, 1]\n",
    "for i, seed in enumerate(CONFIG['seeds']):\n",
    "    ax.plot(training_history[seed]['val_loss'], label=f'Seed {seed}', color=colors[i], linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Validation Loss', fontsize=12)\n",
    "ax.set_title('Validation Loss Curves', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Validation Accuracy\n",
    "ax = axes[1, 0]\n",
    "for i, seed in enumerate(CONFIG['seeds']):\n",
    "    ax.plot(training_history[seed]['val_acc'], label=f'Seed {seed}', color=colors[i], linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Validation Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Validation Accuracy Curves', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Validation AUROC\n",
    "ax = axes[1, 1]\n",
    "for i, seed in enumerate(CONFIG['seeds']):\n",
    "    ax.plot(training_history[seed]['val_auroc'], label=f'Seed {seed}', color=colors[i], linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Validation AUROC (%)', fontsize=12)\n",
    "ax.set_title('Validation AUROC Curves', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('ResNet-50 Baseline Training on ISIC 2018\\n(3 Seeds for Statistical Robustness)', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig_path = CONFIG['results_dir'] / 'training_curves.png'\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"‚úÖ Saved: {fig_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ec3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 11: VISUALIZATION - FINAL RESULTS BAR CHART\n",
    "# ============================================================================\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metrics = ['Accuracy', 'Balanced Acc', 'AUROC', 'F1 (macro)']\n",
    "metric_keys = ['accuracy', 'balanced_accuracy', 'auroc', 'f1_macro']\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "for i, seed in enumerate(CONFIG['seeds']):\n",
    "    values = [all_seed_results[seed][k] for k in metric_keys]\n",
    "    bars = ax.bar(x + i*width, values, width, label=f'Seed {seed}', color=colors[i], alpha=0.8)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, values):\n",
    "        ax.annotate(f'{val:.1f}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                   xytext=(0, 3), textcoords='offset points', ha='center', fontsize=9)\n",
    "\n",
    "ax.set_ylabel('Score (%)', fontsize=12)\n",
    "ax.set_title('Baseline Model Performance by Seed\\nISIC 2018 Test Set', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metrics, fontsize=11)\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_path = CONFIG['results_dir'] / 'seed_comparison.png'\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"‚úÖ Saved: {fig_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32281f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 12: FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE 3 COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìä BASELINE MODEL PERFORMANCE (Mean ¬± Std):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"   Accuracy:      {aggregated['accuracy']['mean']:.2f}% ¬± {aggregated['accuracy']['std']:.2f}%\")\n",
    "print(f\"   Balanced Acc:  {aggregated['balanced_accuracy']['mean']:.2f}% ¬± {aggregated['balanced_accuracy']['std']:.2f}%\")\n",
    "print(f\"   AUROC:         {aggregated['auroc']['mean']:.2f}% ¬± {aggregated['auroc']['std']:.2f}%\")\n",
    "print(f\"   F1 (macro):    {aggregated['f1_macro']['mean']:.2f}% ¬± {aggregated['f1_macro']['std']:.2f}%\")\n",
    "\n",
    "print(\"\\nüìÅ SAVED CHECKPOINTS:\")\n",
    "print(\"-\" * 50)\n",
    "for seed in CONFIG['seeds']:\n",
    "    ckpt_path = CONFIG['checkpoint_dir'] / f'seed_{seed}' / 'best.pt'\n",
    "    if ckpt_path.exists():\n",
    "        size_mb = ckpt_path.stat().st_size / (1024*1024)\n",
    "        print(f\"   ‚úÖ seed_{seed}/best.pt ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå seed_{seed}/best.pt - NOT FOUND\")\n",
    "\n",
    "print(\"\\nüéØ NEXT STEPS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"   1. Run Phase 4 notebook for adversarial robustness evaluation\")\n",
    "print(\"   2. Use these checkpoints as baseline comparison\")\n",
    "print(\"   3. Proceed to Phase 5 tri-objective robust training\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ PHASE 3 BASELINE TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
