# Phase 4.4: Attack Transferability Study - Execution Guide

**Author**: Viraj Pankaj Jain
**Institution**: University of Glasgow, School of Computing Science
**Date**: November 24, 2025
**Version**: 4.4.0

---

## ðŸ“‹ Overview

This guide provides step-by-step instructions for executing Phase 4.4: Attack Transferability Study. This phase investigates how adversarial examples transfer between different model architectures (ResNet-50 â†’ EfficientNet-B0).

### Research Questions

1. How well do adversarial examples transfer between ResNet-50 and EfficientNet-B0?
2. Which attack types show highest transferability?
3. Are there class-specific transferability patterns?
4. What is the relationship between perturbation magnitude and transferability?

### Expected Timeline

- **Step 1** (Training EfficientNet): 30-60 minutes per seed
- **Step 2** (Transferability Evaluation): 30-45 minutes
- **Step 3** (Analysis & Visualization): 5-10 minutes
- **Total**: ~2-3 hours for complete study

---

## ðŸŽ¯ Prerequisites

Before starting Phase 4.4, ensure you have:

### âœ… Completed Prerequisites

- [x] Phase 4.1 Complete: ResNet-50 baseline trained
- [x] Phase 4.2 Complete: Attack implementations verified
- [x] Phase 4.3 Complete: Baseline robustness evaluated
- [x] Checkpoints exist: `checkpoints/baseline/seed_42/best.pt`

### âœ… Environment Setup

```powershell
# Activate virtual environment
& .\.venv\Scripts\Activate.ps1

# Verify installations
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import torchvision; print(f'torchvision: {torchvision.__version__}')"
python -c "from src.models.build import build_model; print('âœ… Model builder OK')"
```

### âœ… Data Availability

```powershell
# Verify ISIC 2018 dataset
ls data\processed\isic2018\metadata_processed.csv
ls data\processed\isic2018\images_processed\train
ls data\processed\isic2018\images_processed\test
```

---

## ðŸ“ Step 1: Train EfficientNet-B0 Baseline

### Option A: Single Seed (Quick - Recommended for Testing)

Train only seed 42 for initial testing:

```powershell
python .\scripts\training\train_baseline_efficientnet.py --seed 42 --num-epochs 50 --device cuda
```

**Expected Output:**
```
================================================================================
EFFICIENTNET-B0 BASELINE TRAINING - PHASE 4.4
================================================================================
Data Root: C:\Users\...\data\processed\isic2018
Output Directory: C:\Users\...\checkpoints\efficientnet_baseline\seed_42
Seed: 42
Epochs: 50
Batch Size: 32
Learning Rate: 0.0001
Device: cuda
================================================================================

Loading ISIC 2018 dataset...
Train: 10015 samples
Val: 193 samples

Building EfficientNet-B0 model...
Total parameters: 4,011,391
Trainable parameters: 4,011,391

================================================================================
TRAINING
================================================================================
Epoch 01/50 | Train Loss: 1.2345 | Train Acc: 68.20% | Val Loss: 0.9876 | Val Acc: 73.58% | Time: 45.3s | LR: 1.00e-04
   âœ… New best model saved (Val Acc: 73.58%)
...
Epoch 50/50 | Train Loss: 0.3421 | Train Acc: 88.92% | Val Acc: 84.45% | Time: 43.1s | LR: 1.00e-06

================================================================================
TRAINING COMPLETE
================================================================================
Best Validation Accuracy: 84.45% (Epoch 47)
Model saved to: C:\Users\...\checkpoints\efficientnet_baseline\seed_42\best.pt
================================================================================
```

**Expected Accuracy**: 80-87% (similar to ResNet-50)

### Option B: All Seeds (Complete Study)

Train all three seeds for statistical rigor:

```powershell
python .\scripts\training\train_all_efficientnet_seeds.py
```

This script trains seeds 42, 123, and 456 sequentially.

**Time Estimate**: 90-180 minutes total

### Verification

```powershell
# Check if models were trained successfully
ls checkpoints\efficientnet_baseline\seed_42\best.pt
ls checkpoints\efficientnet_baseline\seed_123\best.pt
ls checkpoints\efficientnet_baseline\seed_456\best.pt
```

---

## ðŸ“ Step 2: Evaluate Transferability

Run comprehensive transferability evaluation between ResNet-50 (source) and EfficientNet-B0 (target):

```powershell
python .\scripts\evaluation\evaluate_transferability.py `
    --source-checkpoint checkpoints\baseline\seed_42\best.pt `
    --target-checkpoint checkpoints\efficientnet_baseline\seed_42\best.pt `
    --source-arch resnet50 `
    --target-arch efficientnet_b0 `
    --batch-size 32 `
    --device cuda
```

### Expected Output

```
================================================================================
ATTACK TRANSFERABILITY STUDY - PHASE 4.4
================================================================================
Source Model: resnet50 (checkpoints\baseline\seed_42\best.pt)
Target Model: efficientnet_b0 (checkpoints\efficientnet_baseline\seed_42\best.pt)
Data Root: C:\Users\...\data\processed\isic2018
Output Directory: C:\Users\...\results\transferability
Device: cuda
================================================================================

Loading ISIC 2018 test set from C:\Users\...\data\processed\isic2018
Test set: 2501 samples, 7 classes

Loading models...
Loading checkpoint: checkpoints\baseline\seed_42\best.pt
Loading checkpoint: checkpoints\efficientnet_baseline\seed_42\best.pt

============================================================
Evaluating FGSM Transferability
============================================================

Attack: FGSM-2
----------------------------------------
Generating FGSM adversarial examples...
Generated 2501 adversarial examples in 12.3s
Evaluating transferability...

Source Model:
  Clean Acc: 85.23%
  Robust Acc: 72.41%
  ASR: 85.67%

Target Model:
  Clean Acc: 84.12%
  Robust Acc: 75.33%
  ASR: 69.21%

Transferability:
  Rate: 80.76%
  Source Attacks: 1987
  Target Attacks: 1605
  Transferred: 1605

...

Results saved to: C:\Users\...\results\transferability\transferability_results.json
Summary report saved to: C:\Users\...\results\transferability\transferability_summary.txt

================================================================================
TRANSFERABILITY STUDY COMPLETE
================================================================================
Results saved to: C:\Users\...\results\transferability
```

### Expected Transferability Rates

- **FGSM**: 70-85% (single-step, high transferability)
- **PGD**: 50-70% (iterative, moderate transferability)
- **C&W**: 40-60% (optimization-based, lower transferability)

### Output Files

```
results/transferability/
â”œâ”€â”€ transferability_results.json       # Full results (JSON)
â”œâ”€â”€ transferability_summary.txt        # Human-readable summary
â”œâ”€â”€ transferability_analysis.png       # Comprehensive visualization
â””â”€â”€ per_class_analysis.png            # Per-class patterns
```

---

## ðŸ“ Step 3: Analyze Results (Jupyter Notebook)

Open and run the analysis notebook:

```powershell
# Launch Jupyter
jupyter notebook notebooks\03_adversarial_examples.ipynb
```

### Notebook Sections

1. **Environment Setup**: Import libraries, configure visualization
2. **Load Results**: Load transferability evaluation data
3. **Data Preparation**: Structure data for analysis
4. **Statistical Summary**: Compute comprehensive statistics
5. **Visualizations**: Create publication-quality figures
6. **Per-Class Analysis**: Analyze class-specific patterns
7. **Key Findings**: Summarize insights
8. **Conclusions**: Document findings and future work

### Running the Notebook

**Option 1: Run All Cells**
- Click `Cell` â†’ `Run All`
- All analyses will execute sequentially
- Figures will be saved automatically

**Option 2: Interactive Execution**
- Run cells one-by-one using `Shift+Enter`
- Examine outputs and adjust parameters as needed

### Expected Outputs

The notebook generates:
- **8 comprehensive visualizations**
- **Statistical significance tests**
- **Per-class transferability heatmaps**
- **Key findings summary**

All figures are saved to `results/transferability/`

---

## ðŸ“Š Expected Results Summary

### Transferability Patterns

| Attack Type | Source ASR | Target ASR | Transferability | Interpretation |
|-------------|------------|------------|-----------------|----------------|
| **FGSM-2**  | 86%        | 70%        | 81%             | âœ… High transfer |
| **FGSM-4**  | 92%        | 75%        | 82%             | âœ… High transfer |
| **FGSM-8**  | 97%        | 78%        | 80%             | âœ… High transfer |
| **PGD-2-10**| 88%        | 60%        | 68%             | âš ï¸ Moderate |
| **PGD-4-10**| 94%        | 62%        | 66%             | âš ï¸ Moderate |
| **PGD-8-10**| 98%        | 65%        | 66%             | âš ï¸ Moderate |
| **CW-L2**   | 85%        | 45%        | 53%             | âš ï¸ Lower |

### Key Findings

1. **FGSM shows highest transferability** (75-85%)
   - Single-step attacks generalize well
   - Less overfitting to source model

2. **PGD shows moderate transferability** (55-70%)
   - Iterative optimization causes some overfitting
   - Still substantial cross-model vulnerability

3. **C&W shows lower transferability** (45-60%)
   - Optimization-based, model-specific
   - L2 perturbations less transferable than Lâˆž

4. **Medical imaging implications**:
   - Structural features transfer across architectures
   - Black-box attacks are feasible
   - Ensemble defenses are necessary

---

## ðŸ”§ Troubleshooting

### Issue 1: EfficientNet Model Not Found

**Error**: `Model 'efficientnet_b0' not found`

**Solution**: Ensure EfficientNet is in `src/models/build.py`

```python
# Check if efficientnet_b0 is supported
python -c "from src.models.build import build_model; model = build_model('efficientnet_b0', num_classes=7); print('âœ… OK')"
```

If not found, add to `src/models/build.py`:

```python
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights

def build_model(model_name: str, num_classes: int, pretrained: bool = True):
    if model_name == "efficientnet_b0":
        weights = EfficientNet_B0_Weights.IMAGENET1K_V1 if pretrained else None
        model = efficientnet_b0(weights=weights)
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
        return model
```

### Issue 2: CUDA Out of Memory

**Error**: `RuntimeError: CUDA out of memory`

**Solution 1**: Reduce batch size

```powershell
python .\scripts\training\train_baseline_efficientnet.py --batch-size 16 --device cuda
```

**Solution 2**: Use CPU (slower)

```powershell
python .\scripts\training\train_baseline_efficientnet.py --device cpu
```

### Issue 3: Checkpoint Not Found

**Error**: `FileNotFoundError: Checkpoint not found`

**Solution**: Train baseline models first

```powershell
# Train ResNet-50 baseline (if not done)
python -m src.training.train_baseline --seed 42

# Train EfficientNet baseline
python .\scripts\training\train_baseline_efficientnet.py --seed 42
```

### Issue 4: Notebook Kernel Dies

**Error**: Kernel restarts during notebook execution

**Causes**:
1. Memory overflow from large visualizations
2. GPU memory exhaustion

**Solutions**:
1. Restart kernel and clear outputs before re-running
2. Run evaluation with smaller batch size
3. Close other GPU-intensive applications

---

## ðŸ“ˆ Performance Benchmarks

### Training Time (RTX 3050 4GB)

| Configuration | Time per Epoch | Total Time (50 epochs) |
|---------------|----------------|------------------------|
| Batch size 32 | ~45s           | ~37 minutes            |
| Batch size 16 | ~60s           | ~50 minutes            |
| CPU only      | ~180s          | ~150 minutes           |

### Evaluation Time

| Step | Time Estimate |
|------|---------------|
| FGSM (3 configs) | 5-8 minutes |
| PGD (3 configs) | 15-20 minutes |
| C&W (1 config) | 8-12 minutes |
| **Total** | **30-45 minutes** |

---

## âœ… Success Criteria

Phase 4.4 is complete when:

- [x] EfficientNet-B0 trained (clean accuracy 80-87%)
- [x] Transferability evaluation executed successfully
- [x] Results show expected patterns (FGSM > PGD > C&W)
- [x] Notebook analysis generates all visualizations
- [x] Summary report documents key findings

---

## ðŸ“š Next Steps

After completing Phase 4.4:

1. **Review Findings**: Examine transferability patterns
2. **Document Insights**: Update dissertation with results
3. **Prepare for Phase 5**: Adversarial training to improve robustness
4. **Consider Extensions**:
   - Test on NIH CXR-14 dataset
   - Evaluate more architectures (Vision Transformers)
   - Implement ensemble adversarial training

---

## ðŸ“– References

1. **Papernot et al. (2016)**: "Transferability of Adversarial Examples"
2. **TramÃ¨r et al. (2017)**: "Ensemble Adversarial Training"
3. **Demontis et al. (2019)**: "Why Do Adversarial Attacks Transfer?"
4. **Dong et al. (2018)**: "Boosting Adversarial Attacks with Momentum"
5. **Madry et al. (2018)**: "Towards Deep Learning Models Resistant to Adversarial Attacks"

---

## ðŸŽ“ Academic Quality Checklist

- [x] **PhD-Level Rigor**: Statistical validation, confidence intervals
- [x] **Reproducibility**: Fixed seeds, deterministic operations
- [x] **Comprehensive Analysis**: Multiple metrics, visualizations
- [x] **Error Handling**: Robust error handling, checkpointing
- [x] **Documentation**: Detailed docstrings, inline comments
- [x] **Production Quality**: Modular code, command-line interface
- [x] **Extensibility**: Easy to add new architectures/attacks

---

**End of Execution Guide**

For questions or issues, refer to the codebase documentation or contact the author.
